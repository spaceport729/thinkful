{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
       "0    CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
       "1    CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
       "2    CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
       "3    CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
       "4    CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
       "\n",
       "   gndr  agea  partner  \n",
       "0   2.0  60.0      1.0  \n",
       "1   2.0  59.0      1.0  \n",
       "2   1.0  24.0      2.0  \n",
       "3   2.0  64.0      1.0  \n",
       "4   2.0  55.0      1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAETCAYAAACobePkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22b14df2ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22b15229ac8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAERCAYAAADonmWBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZlaHg6OZWR0OjmZmdfx/NTC8Ioznv28AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22b14fd9400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = df.corr()\n",
    "sns.heatmap(corrmat, vmax=.8, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRILL: Improve this gradient boost model\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement. Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set. Strategies you might use include:\n",
    "1. Creating new features\n",
    "2. Applying more overfitting-prevention strategies like subsampling\n",
    "3. More iterations\n",
    "4. Trying a different loss function\n",
    "5. Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.033278777959629025\n",
      "Percent Type II errors: 0.11974904528096017\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.1116564417177914\n",
      "Percent Type II errors: 0.17423312883435582\n"
     ]
    }
   ],
   "source": [
    "# increasing the iterations to 20000, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 20000,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combining the correlated features\n",
    "\n",
    "means = X[['ppltrst','pplfair','pplhlp']].mean(axis=0)\n",
    "stds = X[['ppltrst','pplfair','pplhlp']].std(axis=0)\n",
    "X_New_Features['trust_fair_help'] = ((df[['ppltrst','pplfair','pplhlp']] - means) / stds).mean(axis=1)\n",
    "\n",
    "X_New_Features = X_New_Features.drop(['ppltrst','pplfair','pplhlp'],axis=1)\n",
    "X_New_Features['age_squared'] = X_New_Features['agea'] * X_New_Features['agea']\n",
    "# Create training and test sets.\n",
    "offset = int(X_New_Features.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train_nf, y_train = X_New_Features[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test_nf, y_test = X_New_Features[offset:], y[offset:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.02618657937806874\n",
      "Percent Type II errors: 0.09997272231314784\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0736196319018405\n",
      "Percent Type II errors: 0.19754601226993865\n"
     ]
    }
   ],
   "source": [
    "# increasing the iterations to 20000, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 20000,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train_nf, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train_nf)\n",
    "predict_test = clf.predict(X_test_nf)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>CH</th>\n",
       "      <th>CZ</th>\n",
       "      <th>DE</th>\n",
       "      <th>ES</th>\n",
       "      <th>NO</th>\n",
       "      <th>SE</th>\n",
       "      <th>trust_fair_help</th>\n",
       "      <th>age_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191246</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020453</td>\n",
       "      <td>3481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.090626</td>\n",
       "      <td>576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321425</td>\n",
       "      <td>4096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170892</td>\n",
       "      <td>3025.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  tvtot  happy  sclmeet  sclact  gndr  agea  CH  CZ  DE  ES  NO  SE  \\\n",
       "0     6    3.0    8.0      5.0     4.0   2.0  60.0   1   0   0   0   0   0   \n",
       "1     6    6.0    9.0      3.0     2.0   2.0  59.0   1   0   0   0   0   0   \n",
       "2     6    1.0    7.0      6.0     3.0   1.0  24.0   1   0   0   0   0   0   \n",
       "3     6    4.0   10.0      6.0     2.0   2.0  64.0   1   0   0   0   0   0   \n",
       "4     6    5.0    8.0      7.0     2.0   2.0  55.0   1   0   0   0   0   0   \n",
       "\n",
       "   trust_fair_help  age_squared  \n",
       "0         0.191246       3600.0  \n",
       "1         0.020453       3481.0  \n",
       "2         1.090626        576.0  \n",
       "3         0.321425       4096.0  \n",
       "4         0.170892       3025.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_New_Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.16441717791411042\n",
      "Percent Type II errors: 0.1705521472392638\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from matplotlib.mlab import PCA as mlabPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sklearn_pca = PCA(n_components=10)\n",
    "features_sklearn = sklearn_pca.fit_transform(X_New_Features)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train_pca, y_train = features_sklearn[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test_pca, y_test = features_sklearn[offset:], y[offset:]\n",
    "\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train_pca)\n",
    "predict_test = clf.predict(X_test_pca)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA seems to result in perfect prediction of the training set but poor prediction of the test set (overfitting)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.10306748466257669\n",
      "Percent Type II errors: 0.17791411042944785\n"
     ]
    }
   ],
   "source": [
    "# increasing the iterations to 20000, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 10000,\n",
    "          'max_depth': 5,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train_nf, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train_nf)\n",
    "predict_test = clf.predict(X_test_nf)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03723404255319149\n",
      "Percent Type II errors: 0.1362520458265139\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08711656441717791\n",
      "Percent Type II errors: 0.17177914110429449\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## age was influential - what if I made it categorical and then made a dummy feature set?\n",
    "X_nf_age=X_New_Features.drop(['agea'],axis=1)\n",
    "X_nf_age['60_Plus'] = np.where(X_New_Features['agea']>=60, 1, 0)\n",
    "\n",
    "\n",
    " # Put 90% of the data in the training set.\n",
    "X_train_nf_age, y_train = X_nf_age[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test_nf_age, y_test = X_nf_age[offset:], y[offset:]\n",
    "# increasing the iterations to 20000, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 5000,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance',\n",
    "          'subsample': 1.0}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train_nf_age, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train_nf_age)\n",
    "predict_test = clf.predict(X_test_nf_age)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
