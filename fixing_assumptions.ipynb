{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meeting Assumptions for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumptions in linear regression\n",
    "\n",
    "##### 1: linear relationship\n",
    "    - features in a regression need to have a linear relationship with the outcome. \n",
    "    - Sometimes this can be fixed by applying a non-linear transformation function to a feature. \n",
    "##### 2: multivariate normality\n",
    "    - The error from the model (calculated by subtracting the model-predicted values from the real outcome values) should be normally distributed   \n",
    "    - Outliers or skewness in error can often be traced back to outliers or skewness in data.\n",
    "##### 3: homoscedasticity \n",
    "    - distribution of your error terms (its \"scedasticity\"), should be consistent for all predicted values, or homoscedastic.(if your error terms aren't consistently distributed and you have more variance in the error for large outcome values than for small ones, then the confidence interval for large predicted values will be too small because it will be based on the average error variance. This leads to overconfidence in the accuracy of your model's predictions.)\n",
    "    -Some fixes to heteroscedasticity include transforming the dependent variable and adding features that target the poorly-estimated areas. For example, if a model tracks data over time and model error variance jumps in the September to November period, a binary feature indicating season may be enough to resolve the problem.\n",
    "##### 4: low multicollinearity\n",
    "    - Correlations among features should be low or nonexistent.\n",
    "    - Multicollinearity can be fixed by PCA or by discarding some of the correlated features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potential Corrections for Homoscedasticity:\n",
    "\n",
    "##### 1.Data transformations\n",
    "\n",
    "1. Take the square root of the features\n",
    "new_feature = np.sqrt(df_house_sales_numerical['sqft_living'])),bins=50)\n",
    "2. Take the log of the feature\n",
    "new_feature = np.log(df_house_sales_numerical[\"sqft_living\"].astype(float))\n",
    "3. Take inverse of the feature\n",
    "new_feature = 1/df_house_sales_numerical[\"sqft_lot\"].astype(float)\n",
    "4. Take exponential of the feature\n",
    "new_feature = np.exp(df_house_sales_numerical[\"sqft_living\"].astype(float))\n",
    "\n",
    "##### 2. New features to target poorly-estimated areas\n",
    "\n",
    "new_feature = np.where(df_house_sales_numerical_minus_outliers['sqft_lot_sqrt'] < 50, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potential Corrections for Multivariate non-normality:\n",
    "\n",
    "1. Removing outliers (outside of 1.5x IQR)\n",
    "\n",
    "#sort values\n",
    "df_house_sales_numerical.sort_values('sqft_living', inplace=True)\n",
    "df_house_sales_numerical.sort_values('sqft_lot', inplace=True)\n",
    "df_house_sales_numerical.sort_values('sqft_living15', inplace=True)\n",
    "\n",
    "#identify IQR for sqft_living\n",
    "Q1_living = df_house_sales_numerical['sqft_living'].quantile(0.25)\n",
    "Q3_living = df_house_sales_numerical['sqft_living'].quantile(0.75)\n",
    "IQR_living = Q3_living - Q1_living\n",
    "\n",
    "#identify IQR for sqft_living15\n",
    "Q1_living15 = df_house_sales_numerical['sqft_living15'].quantile(0.25)\n",
    "Q3_living15 = df_house_sales_numerical['sqft_living15'].quantile(0.75)\n",
    "IQR_living15 = Q3_living15 - Q1_living15\n",
    "\n",
    "#identify IQR for sqft lot\n",
    "Q1_lot = df_house_sales_numerical['sqft_lot'].quantile(0.25)\n",
    "Q3_lot = df_house_sales_numerical['sqft_lot'].quantile(0.75)\n",
    "IQR_lot = Q3_lot - Q1_lot\n",
    "\n",
    "#perform query that limits records to those that fall in the IQR for sqft_living, sqft_lot, sqft_living15\n",
    "df_house_sales_numerical_minus_outliers = df_house_sales_numerical.query('(@Q1_living - 1.5 * @IQR_living) <= sqft_living <= (@Q3_living + 1.5 * @IQR_living) & \\\n",
    "(@Q1_living15 - 1.5 * @IQR_living15) <= sqft_living15 <= (@Q3_living15 + 1.5 * @IQR_living15)& \\\n",
    "(@Q1_lot - 1.5 * @IQR_lot) <= sqft_lot <= (@Q3_lot + 1.5 * @IQR_lot)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
