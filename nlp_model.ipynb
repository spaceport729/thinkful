{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this challenge, you will need to choose a corpus of data from nltk or another source that includes categories you can predict and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "1. Data cleaning / processing / language parsing\n",
    "2. Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "3. Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "4. Assess your models using cross-validation and determine whether one model performed better.\n",
    "5. Pick one of the models and try to increase accuracy by at least 5 percentage points.\n",
    "6. Write up your report in a Jupyter notebook. Be sure to explicitly justify the choices you make throughout, and submit it below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data loading/cleaning/processing/language parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import time\n",
    "import itertools\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning / processing / language parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHARLES M. BLOW', 'DAVID BROOKS', 'FRANK BRUNI', 'ROGER COHEN', 'GAIL COLLINS', 'ROSS DOUTHAT', 'MAUREEN DOWD', 'THOMAS L. FRIEDMAN', 'MICHELLE GOLDBERG', 'NICHOLAS KRISTOF', 'PAUL KRUGMAN', 'DAVID LEONHARDT', 'ANDREW ROSENTHAL', 'BRET STEPHENS']\n"
     ]
    }
   ],
   "source": [
    "# create list of opinion writers at nytimes\n",
    "writers = ['Charles M. Blow','David Brooks','Frank Bruni','Roger Cohen','Gail Collins',\n",
    "          'Ross Douthat','Maureen Dowd','Thomas L. Friedman','Michelle Goldberg','Nicholas Kristof',\n",
    "          'Paul Krugman','David Leonhardt','Andrew Rosenthal','Bret Stephens']\n",
    "writers = [x.upper() for x in writers]\n",
    "print(writers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>byline</th>\n",
       "      <th>date</th>\n",
       "      <th>full_text</th>\n",
       "      <th>subjects</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDREW ROSENTHAL</td>\n",
       "      <td>2017-10-19</td>\n",
       "      <td>When most Americans think of domestic terroris...</td>\n",
       "      <td>['Blacks', 'Police Brutality, Misconduct and S...</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDREW ROSENTHAL</td>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>It’s time to talk about taking away guns — not...</td>\n",
       "      <td>['Gun Control', 'Firearms', 'Las Vegas, Nev, S...</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDREW ROSENTHAL</td>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>In normal times, the appointment of a former F...</td>\n",
       "      <td>['Special Prosecutors (Independent Counsel)']</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAVID LEONHARDT</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>This article is part of the Opinion Today news...</td>\n",
       "      <td>['United States Politics and Government', 'Tax...</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DAVID LEONHARDT</td>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>This article is part of the Opinion Today news...</td>\n",
       "      <td>['Taxation', 'Baseball', 'Officiating (Sports)...</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             byline       date  \\\n",
       "0  ANDREW ROSENTHAL 2017-10-19   \n",
       "1  ANDREW ROSENTHAL 2017-10-04   \n",
       "2  ANDREW ROSENTHAL 2017-05-18   \n",
       "3   DAVID LEONHARDT 2017-11-29   \n",
       "4   DAVID LEONHARDT 2017-11-02   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  When most Americans think of domestic terroris...   \n",
       "1  It’s time to talk about taking away guns — not...   \n",
       "2  In normal times, the appointment of a former F...   \n",
       "3  This article is part of the Opinion Today news...   \n",
       "4  This article is part of the Opinion Today news...   \n",
       "\n",
       "                                            subjects  word_count  \n",
       "0  ['Blacks', 'Police Brutality, Misconduct and S...         753  \n",
       "1  ['Gun Control', 'Firearms', 'Las Vegas, Nev, S...         776  \n",
       "2      ['Special Prosecutors (Independent Counsel)']         686  \n",
       "3  ['United States Politics and Government', 'Tax...         528  \n",
       "4  ['Taxation', 'Baseball', 'Officiating (Sports)...         725  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data from json - full text of op ed articles from ny times\n",
    "op_ed_articles = pd.read_json('nytimes_oped_articles.json')\n",
    "#print(op_ed_articles['full_text'][2])\n",
    "op_ed_articles = op_ed_articles.reset_index(drop=True)\n",
    "op_ed_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):    \n",
    "     # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # remove parentheses\n",
    "    text = re.sub(\"[\\(|\\)]\", \"\", text)\n",
    "    # remove non-ascii characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]','', text)\n",
    "    # remove single character words\n",
    "    #text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    # remove double hyphen\n",
    "    text = re.sub(r'--','-',text)\n",
    "    # regular expression that replaces brackets and anything between them with nothing\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean up the text \n",
    "for index, row in op_ed_articles.iterrows():\n",
    "        i = row['full_text'].lower()\n",
    "        i = text_cleaner(i)\n",
    "        op_ed_articles.loc[index, \"full_text\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "nlp = spacy.load('en')\n",
    "op_ed_articles['full_text_tokenized'] = op_ed_articles['full_text'].apply(lambda x: nlp(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features using two different NLP methods: For example, BoW vs tf-idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create train/test dataset for full texts\n",
    "y = op_ed_articles['byline']\n",
    "X = op_ed_articles.drop(['byline'],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text_tokenized</th>\n",
       "      <th>byline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(when, most, americans, think, of, domestic, t...</td>\n",
       "      <td>ANDREW ROSENTHAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(its, time, to, talk, about, taking, away, gun...</td>\n",
       "      <td>ANDREW ROSENTHAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(in, normal, times, ,, the, appointment, of, a...</td>\n",
       "      <td>ANDREW ROSENTHAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(this, article, is, part, of, the, opinion, to...</td>\n",
       "      <td>DAVID LEONHARDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(this, article, is, part, of, the, opinion, to...</td>\n",
       "      <td>DAVID LEONHARDT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 full_text_tokenized            byline\n",
       "0  (when, most, americans, think, of, domestic, t...  ANDREW ROSENTHAL\n",
       "1  (its, time, to, talk, about, taking, away, gun...  ANDREW ROSENTHAL\n",
       "2  (in, normal, times, ,, the, appointment, of, a...  ANDREW ROSENTHAL\n",
       "3  (this, article, is, part, of, the, opinion, to...   DAVID LEONHARDT\n",
       "4  (this, article, is, part, of, the, opinion, to...   DAVID LEONHARDT"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame with an entry per sentence for the training set\n",
    "combine_Xtrain_ytrain = pd.concat([X,y],axis=1)\n",
    "combine_Xtrain_ytrain = combine_Xtrain_ytrain.drop(['date','subjects','word_count','full_text'],axis=1)\n",
    "combine_Xtrain_ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>full_text_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(steve, bannon, may, no, longer, be, physicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(leadership, ,, breitbart, has, given, favorab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(and, spencer, loves, it.yes, ,, that, richard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(that, was, the, same, protest, about, which, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(i, do, nt, think, it, has, done, this, delibe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(12, ,, the, wall, street, journal, reported, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(trump, still, frequently, consults, him, ,, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(if, alabama, voters, on, tuesday, elect, roy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(he, is, them, ,, and, they, are, him, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(any, pretense, of, tolerance, and, egalitaria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(last, week, ,, r.n.c, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(chairwoman, ronna, mcdaniel, told, cnn, :, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(the, r.n.c, ., is, the, political, arm, of, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(that, was, when, the, hands, that, toted, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(people, who, support, this, point, of, view, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(,, what, trump, means, when, he, says, ,, mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(people, were, strong, in, the, family.yes, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(mothers, were, frequently, ,, and, without, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(when, marriage, among, slaves, was, allowed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(it, strips, away, ancestral, horror, so, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(it, was, brutal, ,, but, people, were, happy, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(enslavers, were, wrong, ,, but, their, famili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(these, are, all, lies, racists, tell.the, sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(these, republicans, are, willing, to, sacrifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(the, republican, party, is, approaching, a, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(other, republican, voters, remain, defiant.if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(he, will, have, led, to, the, rise, of, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(donald, trump, is, completely, unfit, to, be,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(that, is, an, expression, of, the, shock, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(but, this, is, what, happens, when, you, let,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(your, hostility, toward, minorities, and, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(players, protesting, police, violence, ,, whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(we, see, this, in, the, way, that, your, just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(that, is, not, a, statement, of, opinion, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(!, i, will, fight, for, you, while, hillary, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(community, ,, particularly, to, transgender, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(anyone, who, had, been, at, all, aware, of, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(but, then, ,, as, real, -, time, proof, ,, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(women, came, out, in, droves, to, personally,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(he, commends, and, conforms, to, anyone, who,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(he, is, inherently, a, patriarchal, white, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(trump, is, unacceptable, in, every, possible,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(i, have, lived, my, whole, life, with, a, rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(i, did, nt, know, much, about, politics, or, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(i, only, knew, that, the, former, peanut, -, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(speaking, at, a, dallas, convention, of, chri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(no, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(1, :, get, people, saved, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(no, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(2, :, get, them, baptized, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(no, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(3, :, get, them, registered, to, vote.the, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(that, was, its, branding, ,, if, not, always,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(it, was, as, if, the, foot, soldiers, for, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(they, were, harsh, and, vindictive, like, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(identities.piety, is, now, postscript, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(the, principal, motivation, now, is, anger, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(he, is, mean, and, surly, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(he, is, a, bully, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>(he, is, a, pathological, liar, .)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                full_text_sentences\n",
       "0    CHARLES M. BLOW  (steve, bannon, may, no, longer, be, physicall...\n",
       "1    CHARLES M. BLOW  (leadership, ,, breitbart, has, given, favorab...\n",
       "2    CHARLES M. BLOW  (and, spencer, loves, it.yes, ,, that, richard...\n",
       "3    CHARLES M. BLOW  (that, was, the, same, protest, about, which, ...\n",
       "4    CHARLES M. BLOW  (i, do, nt, think, it, has, done, this, delibe...\n",
       "5    CHARLES M. BLOW  (12, ,, the, wall, street, journal, reported, ...\n",
       "6    CHARLES M. BLOW  (trump, still, frequently, consults, him, ,, a...\n",
       "7    CHARLES M. BLOW  (if, alabama, voters, on, tuesday, elect, roy,...\n",
       "8    CHARLES M. BLOW          (he, is, them, ,, and, they, are, him, .)\n",
       "9    CHARLES M. BLOW  (any, pretense, of, tolerance, and, egalitaria...\n",
       "10   CHARLES M. BLOW                          (last, week, ,, r.n.c, .)\n",
       "11   CHARLES M. BLOW  (chairwoman, ronna, mcdaniel, told, cnn, :, th...\n",
       "12   CHARLES M. BLOW  (the, r.n.c, ., is, the, political, arm, of, t...\n",
       "13   CHARLES M. BLOW  (that, was, when, the, hands, that, toted, the...\n",
       "14   CHARLES M. BLOW  (people, who, support, this, point, of, view, ...\n",
       "15   CHARLES M. BLOW  (,, what, trump, means, when, he, says, ,, mak...\n",
       "16   CHARLES M. BLOW  (people, were, strong, in, the, family.yes, ,,...\n",
       "17   CHARLES M. BLOW  (mothers, were, frequently, ,, and, without, w...\n",
       "18   CHARLES M. BLOW  (when, marriage, among, slaves, was, allowed, ...\n",
       "19   CHARLES M. BLOW  (it, strips, away, ancestral, horror, so, that...\n",
       "20   CHARLES M. BLOW  (it, was, brutal, ,, but, people, were, happy, .)\n",
       "21   CHARLES M. BLOW  (enslavers, were, wrong, ,, but, their, famili...\n",
       "22   CHARLES M. BLOW  (these, are, all, lies, racists, tell.the, sam...\n",
       "23   CHARLES M. BLOW  (these, republicans, are, willing, to, sacrifi...\n",
       "24   CHARLES M. BLOW  (the, republican, party, is, approaching, a, m...\n",
       "25   CHARLES M. BLOW  (other, republican, voters, remain, defiant.if...\n",
       "26   CHARLES M. BLOW  (he, will, have, led, to, the, rise, of, the, ...\n",
       "27   CHARLES M. BLOW  (donald, trump, is, completely, unfit, to, be,...\n",
       "28   CHARLES M. BLOW  (that, is, an, expression, of, the, shock, of,...\n",
       "29   CHARLES M. BLOW  (but, this, is, what, happens, when, you, let,...\n",
       "..               ...                                                ...\n",
       "92   CHARLES M. BLOW  (your, hostility, toward, minorities, and, you...\n",
       "93   CHARLES M. BLOW  (players, protesting, police, violence, ,, whi...\n",
       "94   CHARLES M. BLOW  (we, see, this, in, the, way, that, your, just...\n",
       "95   CHARLES M. BLOW  (that, is, not, a, statement, of, opinion, ,, ...\n",
       "96   CHARLES M. BLOW  (!, i, will, fight, for, you, while, hillary, ...\n",
       "97   CHARLES M. BLOW  (community, ,, particularly, to, transgender, ...\n",
       "98   CHARLES M. BLOW  (anyone, who, had, been, at, all, aware, of, t...\n",
       "99   CHARLES M. BLOW  (but, then, ,, as, real, -, time, proof, ,, th...\n",
       "100  CHARLES M. BLOW  (women, came, out, in, droves, to, personally,...\n",
       "101  CHARLES M. BLOW  (he, commends, and, conforms, to, anyone, who,...\n",
       "102  CHARLES M. BLOW  (he, is, inherently, a, patriarchal, white, su...\n",
       "103  CHARLES M. BLOW  (trump, is, unacceptable, in, every, possible,...\n",
       "104  CHARLES M. BLOW  (i, have, lived, my, whole, life, with, a, rep...\n",
       "105  CHARLES M. BLOW  (i, did, nt, know, much, about, politics, or, ...\n",
       "106  CHARLES M. BLOW  (i, only, knew, that, the, former, peanut, -, ...\n",
       "107  CHARLES M. BLOW  (speaking, at, a, dallas, convention, of, chri...\n",
       "108  CHARLES M. BLOW                                            (no, .)\n",
       "109  CHARLES M. BLOW                      (1, :, get, people, saved, .)\n",
       "110  CHARLES M. BLOW                                            (no, .)\n",
       "111  CHARLES M. BLOW                     (2, :, get, them, baptized, .)\n",
       "112  CHARLES M. BLOW                                            (no, .)\n",
       "113  CHARLES M. BLOW  (3, :, get, them, registered, to, vote.the, re...\n",
       "114  CHARLES M. BLOW  (that, was, its, branding, ,, if, not, always,...\n",
       "115  CHARLES M. BLOW  (it, was, as, if, the, foot, soldiers, for, th...\n",
       "116  CHARLES M. BLOW  (they, were, harsh, and, vindictive, like, the...\n",
       "117  CHARLES M. BLOW         (identities.piety, is, now, postscript, .)\n",
       "118  CHARLES M. BLOW  (the, principal, motivation, now, is, anger, ,...\n",
       "119  CHARLES M. BLOW                      (he, is, mean, and, surly, .)\n",
       "120  CHARLES M. BLOW                              (he, is, a, bully, .)\n",
       "121  CHARLES M. BLOW                 (he, is, a, pathological, liar, .)\n",
       "\n",
       "[122 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe of sentences for bag of words\n",
    "opinions_sentences_training_set = pd.DataFrame(columns=['full_text_sentences','author'])\n",
    "for writer in writers:\n",
    "    for index, row in combine_Xtrain_ytrain.iterrows():\n",
    "        if row['byline'] == writer:\n",
    "            df_temp = pd.DataFrame()\n",
    "            sentences = []\n",
    "            author = writer\n",
    "            sentences = [sent for sent in row['full_text_tokenized'].sents]\n",
    "            df_temp = pd.DataFrame({'full_text_sentences': sentences,'author': author})\n",
    "            opinions_sentences_training_set = pd.concat([opinions_sentences_training_set,df_temp])\n",
    "opinions_sentences_training_set = opinions_sentences_training_set.reset_index(drop=True)\n",
    "opinions_sentences_training_set.head(n=122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "      <td>i know that harvey is heavy on americas heart....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAVID BROOKS</td>\n",
       "      <td>were living in the middle of a national crisis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRANK BRUNI</td>\n",
       "      <td>across the country, college freshmen are settl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROGER COHEN</td>\n",
       "      <td>yangon, myanmar president trump is incidental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GAIL COLLINS</td>\n",
       "      <td>donald trump has just voted in the worst cabin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ROSS DOUTHAT</td>\n",
       "      <td>back when congressional republicans were rolli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MAUREEN DOWD</td>\n",
       "      <td>washington so, with this latest toad jumping f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THOMAS L. FRIEDMAN</td>\n",
       "      <td>i was talking the other day to a wise executiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MICHELLE GOLDBERG</td>\n",
       "      <td>on a friday night last month, i moderated a de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NICHOLAS KRISTOF</td>\n",
       "      <td>for decades, one of the most sanctimonious mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PAUL KRUGMAN</td>\n",
       "      <td>looking at the reactions to republican tax pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DAVID LEONHARDT</td>\n",
       "      <td>this article is part of the opinion today news...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ANDREW ROSENTHAL</td>\n",
       "      <td>when most americans think of domestic terroris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BRET STEPHENS</td>\n",
       "      <td>this is the text of the keynote speech deliver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                      combined_text\n",
       "0      CHARLES M. BLOW  i know that harvey is heavy on americas heart....\n",
       "1         DAVID BROOKS  were living in the middle of a national crisis...\n",
       "2          FRANK BRUNI  across the country, college freshmen are settl...\n",
       "3          ROGER COHEN  yangon, myanmar president trump is incidental ...\n",
       "4         GAIL COLLINS  donald trump has just voted in the worst cabin...\n",
       "5         ROSS DOUTHAT  back when congressional republicans were rolli...\n",
       "6         MAUREEN DOWD  washington so, with this latest toad jumping f...\n",
       "7   THOMAS L. FRIEDMAN  i was talking the other day to a wise executiv...\n",
       "8    MICHELLE GOLDBERG  on a friday night last month, i moderated a de...\n",
       "9     NICHOLAS KRISTOF  for decades, one of the most sanctimonious mor...\n",
       "10        PAUL KRUGMAN  looking at the reactions to republican tax pla...\n",
       "11     DAVID LEONHARDT  this article is part of the opinion today news...\n",
       "12    ANDREW ROSENTHAL  when most americans think of domestic terroris...\n",
       "13       BRET STEPHENS  this is the text of the keynote speech deliver..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a merged text for each writer\n",
    "# Create a new DataFrame with an entry per sentence for the training set\n",
    "combine_Xtext_train_ytrain = pd.concat([X,y],axis=1)\n",
    "combine_Xtext_train_ytrain = combine_Xtext_train_ytrain.drop(['date','subjects','word_count','full_text_tokenized'],axis=1)\n",
    "combine_Xtext_train_ytrain= combine_Xtext_train_ytrain.sort_values(['byline'])\n",
    "# print(combine_Xtext_train_ytrain)\n",
    "\n",
    "\n",
    "df_writer_combined_text = pd.DataFrame()\n",
    "\n",
    "for writer in writers:\n",
    "    writer_text = ''\n",
    "    writer_text_list = []\n",
    "    n=0\n",
    "    for index, row in combine_Xtext_train_ytrain.iterrows():\n",
    "        if row['byline'] == writer:\n",
    "            author = writer\n",
    "            writer_text_list.append(row['full_text'])\n",
    "    writer_text = \" \".join(writer_text_list)\n",
    "    df_temp = pd.DataFrame({'combined_text': writer_text,'author': author},index=[n])\n",
    "    df_writer_combined_text = pd.concat([df_writer_combined_text,df_temp])\n",
    "    n += 1\n",
    "df_writer_combined_text = df_writer_combined_text.reset_index(drop=True)\n",
    "df_writer_combined_text.head(n=20)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "\n",
    "df_writer_combined_text['combined_text_tokenized'] = df_writer_combined_text['combined_text'].apply(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 1000 most common words. \n",
    "\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, words_in_articles):\n",
    "    \n",
    "    # Scaffold the data frame (training data/target dataset) and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=words_in_articles)\n",
    "    df['text_sentence'] = opinions_sentences_training_set['full_text_sentences']\n",
    "    df['text_source'] = opinions_sentences_training_set['author']\n",
    "    df.loc[:, words_in_articles] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "         # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     token.lemma_ in words_in_articles\n",
    "                     and not token.is_punct\n",
    "                     and not token.is_stop\n",
    "    \n",
    "                 )]\n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    " \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'operative', 'justice.but', 'shrug', 'psalm', 'bad', 'police', 'ko', 'outrageous', 'product', 'abraham', 'reversal', 'long', 'mohamm', 'growth', 'exciting', 'frequently', 'at&ts', 'pathetic', 'president', 'hill', 'ethnic', 'inspire', 'cream', 'trip', 'insys', 'obviously', 'exception', 'vehicle', 'conspiracy', 'remember', 'couple', 'reference', 'u.s.o', 'delrahim', 'ban', '2024.the', 'wisconsin', 'coward', 'pro', 'triple', 'ferguson', 'seifert', 'contempt', 'breast', 'compromise', 'ohio', 'inability', 'information', 'cunningham', 'critique', 'handgun', 'ethos', 'ultimate', 'wipe', 'saturday', 'entitled', 'supreme', 'charter', 'thumb', 'hit', 'chip', 'affable', 'suppression', 'tolerate', 'grade', 'accuse', 'depress', 'here', 'wonk', 'little', 'jerusalem', 'tube', 'vice', 'bomb', 'happiness', 'cruel', 'document', 'part', 'post', 'reckoning', 'dinner', 'chait', 'priebus', 'representative', 'stable', 'choose', 'occultism', 'incompetence', 'periodically', 'planet', 'trigger', 'weaken', 'support', 'gary', '2015', 'sherrod', 'educate', 'company', 'specifically', 'legislation', 'eager', 'er', 'exactly', 'partner', 'way', 'record', 'control', 'sunni', 'theocratic', 'punishment', 'are?one', 'clarence', 'indirect', 'period', 'physician', '2003', 'probability', 'opioids', 'executive', 'dramatically', 'iraqis', 'stand', '1.5', 'bomber', 'immediately', 'fall', 'south', 'journey', 'supernatural', 'command', 'treatment', 'recover', 'presidential', 'renew', 'wobbly', 'steele', 'paranoia', 'bright', 'innocent', 'vacation', 'remotely', 'inflow', 'plaintively.the', 'generate', 'somebody', 'tpp', 'hollywood', 'inclusion', 'wrong', 'suit', 'terror', 'approach', 'fusion', 'mugabe', 'cold', 'walk', 'imaginary', 'mick', 'customer', 'manipulate', 'playing', 'judiciary', 'rien', 'sooner', 'juncture', 'fighter', 'linton', 'caucus', 'bipartisan', 'leftist', 'picture', 'job', 'senior', 'soon', 'boomer', 'gorbachev', 'lawmaker', 'powerless', 'pre', '1980', 'league', 'later', 'distance', 'undo', 'jaw', 'martin', 'kong', 'rapper', 'wind', 'smith', 'concern', 'saul', 'reimbursement', 'acceptance', 'historically', 'repeatedly', 'prohibit', 'scandal', 'puppet', 'scientist', 'legacy', 'ploy', 'nazi', 'photograph', 'meeting', 'night', 'kaepernick', 'chauvinist', 'quit', 'animus', 'declare', 'boo', 'guideline', 'nature', 'k.g.b', 'kabul', 'regulation', 'constitutional', 'saint', 'tantalizing', 'soviet', 'enable', 'bill', 'speed', 'beat', 'destroy', 'percentage', 'skierka', 'english', 'endure', 'consolation', 'activity', '450', 'browne', 'dantonio', 'mere', 'left', 'researcher', 'f-22s', 'survivable', 'israeli', 'champion', 'morally', 'group', 'harasser', 'abrupt', 'happy', 'currency', 'like', 'legitimacy', 'king', 'child', 'submit', 'hint', 'flourish', 'cow', 'elevated', 'initiative', 'agent', 'audience', 'un', 'mouth', 'yearn', 'gun.the', 'kuwait', 'leader', 'allegation', 'commander', 'israelis', 'nasty', 'possible', 'hebrew', 'caligula', 'evil', 'spiritual', 'reign', 'instinct', 'instal', 'video', 'author', 'dismay', 'vindicate', 'leg', 'anymore', 'killing', 'key', '2006', 'inch', 'assassinate', 'residence', 'appreciation', 'seems.so', 'subjugation', 'laugh', 'f.b.i', 'birth', 'brutal', 'lincoln', 'multicultural', 'warrant', 'tourist', 'oreo', 'rubin', 'seidman', 'finger', 'lonely', 'belong', 'actualization', 'export', 'photo', 'r.', 'michael', 'brewing', 'clearance', 'drought', 'aile', 'great', 'francis', 'necessary', 'wake', 'constitution', 'ct', 'challenger', 'survey', 'typical', 'trend', 'damaging', 'dismantle', 'bibi', 'donor', 'charlton', 'broad', 'mixture', 'kyi', 'hoffman', 'restaurant', 'sand', '800,000', '11', 'medium', 'misogyny', 'globalization', 'unity', 'gut', 'corporation', 'reason', 'fail', 'council', 'friendship', '130,000', 'car', 'permission', 'drinking', 'sinister', 'appearance', 'quarter', 'realization', 'phone', 'term', 'complaint', 'civility', 'graham', 'urban', 'masculinity', 'participate', 'incentive', 'mcmaster', 'capacity', 'eclipse', 'suspect', 'fossil', 'fargo', 'mis', 'recount', 'negative', 'china', 'sater', 'critic', 'resign', 'defeat', 'remain', 'test', 'reach', 'oklahoma', 'terrorist', 'court', 'evident', 'taxable', 'obstruct', 'calculate', 'deal', 'investigation', 'wednesday', 'corrupt', 'hugely', 'ark', 'plunder', 'unique', 'recusal', 'allege', 'interview', 'research', 'abbie', 'daring', 'overdos', 'kuwaiti', 'commission', 'twisted', 'generally', 'famine', 'knee', 's', 'drutman', 'noble', 'ice', 'whoop', 'defense', 'hefnerian', 'self', 'gillibrand', 'achievement', 'anybody', 'kellyanne', 'friday', 'cheerful', 'christendom', 'forge', 'requirement', 'tune', 'inclined', 'aggressive', 'documentary', 'mcconnell', 'wallow', 'poison', 'class', 'blow', 'paula', 'pain', 'confident.meanwhile', 'teenage', 'anti', 'dominate', 'concept', 'summary', 'articulation', 'cromartie', 'woman', 'privilege', 'brady', 'newsletter', 'family', 'journal', 'spectator', 'thein', 'nauru', 'chicago', 'serial', 'tide', 'british', 'offer', 'patient', 'fascinating', 'infect', 'consumption', 'worth', 'fast', 'intelligence', 'stress', 'govern', 'chairman', 'relative', 'include', 'useful', 'daughter', 'earthquake', 'mullin', 'u.n', 'cagey', 'intimate', 'drumbeat', 'likely', 'populism', 'emblematic', 'strategic', 'jew', 'email', 'coup', 'tactic', 'reckless', 'awaken', 'nonwhite', 'novel', '70', 'been.im', 'houston', 'feature', 'retire', 'file', 'sport', 'thoroughly', 'believer', 'mob', 'big', 'history.even', 'diverse', 'magazine', 'ritz', 'percent', 'poverty', 'pop', 'hopeful', 'nigel', 'barrack', 'possibly', 'palestinian', 'varadkar', 'actor', 'household', 'vocabulary', 'cooperation', 'tech', 'candidate', 'world', 'educated', 'deadly', 'reformation', 'mike', 'freshman', 'memory', 'eat', 'airfield', 'lose', 'lewandowski', 'indictment', 'presidency', 'herald', 'investment', 'quinnipiac', 'indicator', 'democratic', 'reality', 'reduction', 'keep', 'missile', 'desire', 'literally', 'rationality', 'creation', 'nice', 'release', 'barely', 'crimea', 'hatred', '500,000', 'educational', 'corruption', 'lieu', 'surprised', 'reprehensible', 'dismiss', 'internal', 'standing', 'needy', 'meantime', 'increase', 'agenda', 'sanctimonious', 'hedge', 'treason', 'nonsense', 'helm', 'memorial', 'vacuum', 'wray', 'ex', 'error', 'rag', 'supremacist', 'reince', '21st', 'decide', 'angela', 'weird', 'represent', 'granted.the', 'disproportionately', 'vegas', 'home', 'oct', 'cited.the', 'far', 'ambition', 'october', 'nobel', 'average', 'modest', 'islam', 'solution', 'manage', 'expense', 'rubbish', 'responsive', 'responsible', 'sunstein', 'emergency', 'retweet', 'box', 'poor', 'actually', 'bolton', 'murphy', 'lange', 'situation', '1945', 'relatively', 'philosophy', 'value', 'time', 'marine', '5,000', 'amazon', 'inequality', 'flake', 'affirm', 'sexuality', 'swell', 'lowy', 'ann', 'said.i', 'cuck', 'despite', 'editorial', 'turkey', 'vile', 'run', 'emmy', '2005', 'contrast', 'participant', 'evangelicalism', 'entertain', 'prominent', 'dress', 'intend', 'rosenstein', 'pelosi', 'nebraska', 'admirer', 'guidance', 'conversation', 'zuckerberg', 'expression', 'hack', 'view', 'motivate', 'interstate', 'papadopoulos', 'claire', 'contemplate', 'gay', 'slip', 'civilian', 'rape', 'math', 'brazen', 'deference', 'states.we', 'jar', 'anywhere', 'congress', 'illustrate', 'sentence', 'iran', 'excuse', 'heart', 'fly', 'administration', 'bite.the', 'online', 'tendency', 'belief', 'rich', 'reply', 'come', 'permit', 'accept', 'heir', 'fierce', 'credible', 'objection', 'penalty', 'removal', 'pursue', 'sentiment', 'conviction', '20th', 'aftermath', 'defender', 'recent', 'mistress', '700', 'report', 'coverage', 'evidence', 'rocket', 'wealthy', 'low-', 'offense', 'turnbull', 'watson', 'bit', 'goldfein', 'accrue', '13', 'northam', 'mueller', 'testament', 'brussel', 'rob', 'lawyer', 'spell', 'ross', 'roger', 'evaluation', 'manafort', 'mutual', 'brag', '28', 'arakan', 'deadlock', 'screen', 'cheerfully', 'bake', 'shake', 'listen', 'grab', 'instruction', 'recuse', 'governor', 'iraq', 'ego', 'pedophile', 'franken', 'france', 'crazy', 'establishment', 'dangerous', 'doctorate', 'remarkable', 'levinson', 'draw', 'unseat', 'open', 'unit', 'community.the', 'distraction', 'imagine', 'put', 'neighborly', 'extend', 'universalist', 'tricky', 'uncle', 'germany', 'reformer', 'hang', 'bernie', 'coal', 'drop', 'yemen', 'essential', 'surge', 'sun', 'abide', 'signal', 'fanatic', 'neighbor', 'relief', 'launch', 'retirement', 'hall', 'love', 'piece', 'accidentally', 'continuous', 'musk', 'pimp', 'cros', 'would', '25', 'nonetheless', 'appointment', 'answer', 'agency', 'fresh', 'nightclub', 'sack', 'pompeo', 'narrow', 'libya', 'relevant', 'religious', 'vast', 'talent', 'personality', 'columnist', 'avoidance', 'slate', 'kasowitz', 'u.c.l.a', 'hand', 'will', 'escape', 'be', '10', 'scenario', 'degradation', 'afternoon', 'meghan', 'dunham', 'heroin', 'congratulate', 'consent', 'comfort', 'rule', 'inevitable', 'remind', 'escalation', 'kaper', 'populist', 'bring', 'involve', 'march', 'question', 'russia', 'russian', 'anticorruption', 'trial', 'highlight', 'bradys', 'assessment', 'plane', 'interest', 'peer', 'consummate', 'play', 'version', 'erratic', 'oppression', 'christian', 'individualism', 'account', 'leo', 'coulter', 'ugliness', 'act', 'spouse', 'reverse', 'conceal', 'objective', 'cohn', 'imminent', 'premeditated', 'unhinged', 'principle', 'mother', 'dominant', 'ignorance', '21', 'territory', 'selfishness', 'pin', 'monument', 'dog', 'sabotage', 'gas', 'lacking', 'stockholder', 'rightly', 'catastrophe.white', 'sydney', 'honesty', 'strength', '42', 'partly', 'africa', 'club', 'assault.its', 'director', 'fury', 'brock', 'propriety', 'enabler', 'las', 'empower', 'are.im', 'certainty', 'sharing', 'advice', 'surprise', 'gadsden', 'ii', 'plot', 'optimistic', 'dividend', 'seek', 'bed', 'louisville', 'pond', 'prosecute', 'package', 'prepared', 'decay', 'predation', 'imply', 'poorer', 'security', 'parenthood', 'distinction', 'indulge', 'death', 'sorority', 'womb', 'edge', 'proudly', 'breakfast', 'hannity', 'scarcely', 'destructive', 'work', 'anthem', 'mobile', 'grievance', 'pharmaceutical', 'thunder', 'total', 'celebrate', 'goldstone', 'scary', 'forever', 'upset', 'historical', 'hierarchy', 'u.s', 'introduce', 'goldberg', 'gunfire', 'spare', 'share', 'silicon', 'wait', 'dissuasion', 'margin', 'november', 'greatness', 'rid', 'request', 'nero', 'fringe', 'homeland', 'wilderness', 'harass', 'rescue', 'failed.nowhere', 'investigate', 'datum', 'lebanese', 'virtue', 'living', 'thought', 'minnesota', 'vox', 'subject', 'overconfident', 'cast', 'aide', 'pattern', 'altitude', 'bank', 'own', 'benedict', 'found', 'rot', 'alabama', 'infamous', 'aadhaar', 'handle', 'border', 'democracy', 'truth', 'limit', 'ugly', '2001', 'double', 'sit', 'jame', 'pardon', 'cohesion', 'fateful', 'hypodermic', 'issue', 'drive', 'near', 'dot', 'communal', 'cabinet', 'overwhelmingly', 'market', 'western', 'metoo', 'hunter', 'criticize', 'compliment', 'steadily', 'ruin', 'short', 'sept', 'trouble', 'hong', 'special', 'minority', 'voting', 'scene', 'spot', 'beijing', 'confirm', 'weather', 'distract', 'containment', 'bloodthirsty', 'travel', 'con.but', 'center', 'trading', 'blowhard', 'brilliant', 'strongly', 'acknowledge', 'cahn', 'senate', 'c', 'hey', 'team', 'article', 'basic', 'decent', 'wholly', 'combination', 'electric', 'seat', 'twice', 'profile', 'feinstein', 'turn', 'theater', 'kevin', 'alienation', 'chief', 'kennedy', 'prime', 'par', 'ambassador', 'priebuss', 'nt', 'asad', 'reasonably', 'scaramouch', 'instance', 'balance', 'teaching', 'aspect', 'vow', 'trumpian', 'uniform', 'warfare', 'cocaine', 'bogey', 'tv', 'labor', 'mark', 'altogether', 'absolute', 'lobby', 'feminism', 'help', 'tool', 'sin', 'smear', 'universe', 'free', 'ivankas', 'food', 'stand.on', 'kim', 'transcendental', 'nadler', 'pope', 'building', 'heat', 'dictator', 'disclose', 'concentration', 'rush', 'hecker', 'assurance', 'power.o.k', 'threaten', 'positive', 'jerry', 'rent', 'perception', 'wear', 'relaxing', 'rabbi', 'chaos', 'creature', 'suffering', 'sad', 'old', 'private', 'arizona', 'opposition', 'cycle', 'writer', 'laureate', 'deduction', 'atlantic', 'palm', 'suspense', 'spending.and', 'sgt', 'her', 'israels', 'difference', 'predicate', 'substantial', 'probe', 'trust', 'biological', 'extremist', 'torture', 'drag', 'nominee', 'orwellian', 'handful', 'absorb', 'contain', 'worker', 'kick', 'paris', 'pout', 'quote', '5', 'pity', 'notably', 'busy', 'confident', 'dream', 'progressive', 'provision', 'impossible', 'rampant', 'publicist', 'don', 'employee', 'dose', 'damore', 'unlikely.fifty', 'legally', 'weekly', 'tired', 'tenor', 'tooth', 'loser', 'nomination', 'restraint', 'inevitably', 'temporary', 'meeting.the', 'respect', 'abc', 'large', 'viewing', 'unprecedented', 'corporations.but', 'tolerance', 'burn', 'genuinely', 'yes', 'lens', 'churchs', 'suspicion', 'judd', 'practice', 'deem', 'speech', '1990', 'mistakenly', 'nostalgia', 'impose', 'exploit', 'lone', 'covenant', 'warming', 'vague', 'series', 'fiscal', 'mean', 'contraception', 'women', 'up.millennial', 'shot', 'today', '18-year', 'tweeter', 'capitol', 'endorse', 'divorce', 'innovation', 'barro', 'predator', 'megyn', 'devil', 'rally', 'purpose', 'disagreement', 'daca', 'calif', 'empathy', 'shadow', 'bump', 'screening', 'chetty', 'teacher', 'quest', 'machine', 'mosque', 'myth', 'pinnacle', 'lament', 'inventor', 'convince', 'disrupt', 'ignore', 'trait', 'polarization', 'position', 'witchcraft', 'turner', 'shy', 'retreat', 'respond', 'deconstruction', 'curse', '1967', 'buoy', 'fallow', 'separate', 'eiffel', 'faster', 'obscenity', 'up.and', 'camera', 'morality', 'hurricane', 'spur', 'male', 'triumph', 'hate', 'central', 'desjarlais', 'model', 'sexist', 'confrontation', 'scholar', 'blumenthal', 'throughs', 'associate', 'delay', 'teenager', 'foolish', 'number', 'health', 'washington', 'complex', 'napoleon', 'piety', 'cheer', 'care', 'safety', 'table', 'abundance', 'censorship', 'writing', 'color', 'doom', 'echo', 'foreigner', 'meet', 'cheat', 'contrary', 'misery', 'tale', 'bigotry', 'ne', 'fera', 'cite', 'prince', 'thankful.first', 'reader', 'prospect', 'bet', 'denuclearization', 'gag', '27', 'revelation', 'corner', 'potentially', 'flag', 'chapter', 'traditional', 'move', 'alike', 'lord', 'andrew', 'stumble', '6', 'traditionalist', 'misconception', 'actual', 'menace', 'wilson', 'op', 'recommend', 'brief', 'training', 'tree', 'glad', 'heck', 'determine', 'slippery', 'restore', 'patriotism', 'commercial', 'citys', 'phenomenon', 'guam', 'fluid', 'trap', 'barack', 'resolve', 'hear', 'ruler', 'require', 'grave', 'real', 'somewhat', 'testing', 'spy', 'yitzhak', 'eye', 'encounter', 'derive', 'rival', 'preserve', 'outcome', 'main', 'journalist', 'commit', 'back', 'totally', '14', 'reduce', 'cost', 'premarital', 'character', 'rate', 'discipline', 'blog', 'diana', 'straight', 'vertical', '50', 'chapman', 'direction', 'magic', 'tran', 'instant', 'chill', 'interesting', 'disease', 'content', 'violate', 'hardly', 'recognize', 'lifesaving', 'giveaway', 'disappoint', 'targeting', '230,000', 'perfect', 'asset', 'nbc', 'circle', 'semitic', 'vanity', 'icon', 'esteem', 'thug', '100,000', 'race', 'unfamiliar', '1,000', 'topic', 'obituary', 'consolidate', 'addicted', 'grotesque', 'insurance', 'similar', 'trauma', 'stagnation', 'crisis', 'powerful', 'conventional', 'sell', 'yorker', 'influence', 'realize', 'chair', 'children.and', 'excellence', 'occultist', 'remote', 'middleton', 'baghdad', 'economist', 'particular', 'academic', 'challenge', 'collateral', 'denounce', 'ashley', 'member', 'science', 'episode', 'blithely', 'sachs', 'diaspora', 'korea', 'capitalism', 'examine', 'sing', 'guilt', 'australian', 'path', 'forward', 'down.it', 'pregnancy', 'collusion', 'existence', 'plausible', 'radically', '59', 'demand', 'grim', 'inject', 'fabric', 'tribal', 'response', 'doubt', 'frederick', '15', 'dignity', 'pursuit', 'produce', 'lebanon', 'endanger', 'moment', 'silent', 'astonish', 'grasp', 'exemption', 'militia', 'analysis', 'senator', 'farm', 'extreme', 'need', 'giant', 'abuse', 'hypocrisy', '19', 'crow', 'cleansing', 'show', 'transcendence', 'eminence', 'tell', 'playboy', 'wyom', 'truck', 'spear', 'lock', 'reasonable', 'gifford', 'spending', 'ideological', 'polling', 'mobilize', 'revolution', 'tally', 'entrepreneur', 'brother', 'compare', 'personally', 'nazis', 'present', 'forgiveness', 'set', 'obamas', 'citizen', 'officer', 'prefer', 'ram', 'desert', 'relational', 'colleague', 'continent', 'consideration', 'harris', 'overwhelming', 'ahead', 'ticket', 'quickly', 'wary', 'prospector', 'uber', '1.2', 'ron', 'christie', 'ear', 'bath', 'rigorous', 'breitbart', 'step', 'definitely', 'correctly', 'interfere', 'ago', 'covenantal', 'dutton', 'lavish', 'paint', 'surprising', 'cell', 'infinitely', 'obliviousness', 'conference', 'tuesday', 'apply', 'alexander', 'hillary', 'talk', 'extremely', 'type', 'extension', 'humility', 'constituent', 'site', 'gen', 'expert', 'capital', 'bro', 'ostensible', 'biographer', 'contemporary', 'winner', 'organize', 'hole', 'week', 'discussion', 'potent', 'membership', 'syria', 'initially', 'platform', 'last', 'debt', 'testify', 'french', 'pathological', 'cake', 'perform', 'thrust', 'irrational', 'lifeline', 'podesta', 'routinely', 'intellectually', 'faith', 'damage', 'country', 'father', 'guest', 'colbert', 'unable', 'individual', 'interpret', 'castro', 'phase', 'fool', 'argument', 'twist', 'christmas', 'counterpart', 'cowell', 'brutality', 'subsidy', 'spectacular', 'molestation', 'truth.oh', 'incident', 'israel', 'korean', 'sex', 'americans.all', 'discover', 'welcome', 'infrastructure', 'deworm', 'prevention', 'bangladesh', 'girl', 'credulous', 'garden', 'industrys', 'slash', 'plant', 'zeigler', 'crucial', 'slink', 'trump', 'frenzied', 'define', 'align', 'allow', 'congressman', 'result', 'activist', 'extent', 'network', 'aug', 'cowardice', 'supply', 'politician', 'federal', 'todays', 'process', 'brooking', 'bagram', 'economic', 'vulnerable', 'turning', 'bind', 'folk', 'f.', 'putt', 'pharma', 'propaganda', 'know', 'collude', 'apologize', 'identitarianism', 'schedule', 'catland', 'zimmer', 'connecticut', 'offset', 'matthew', 'monday', 'disparage', 'london', 'mainly', 'litman', 'hat', 'traffic', 'cynical', 'boost', 'gazette', 'catholicism', 'decry', 'bakker', 'kyis', 'town', 'goal', 'road', 'alarmed', 'background', 'harassment', 'layer', 'illiberal', 'successful', 'underscore', 'feud', 'striking', 'wickedly', 'blind', 'betrayal', 'longstanding', 'correct', 'true', 'blood', 'salman', 'macron', 'beginning', 'earning', 'money', 'thanksgiv', 'arkansa', 'water', 'nixon', 'willing', 'final', 'expectation', 'economically', 'master', 'smoke', 'brook', 'hurt', 'leer', 'steady', 'netanyahu', 'patent', 'grope', 'save', 'announce', 'squeeze', 'st', 'responsibility', 'negotiation', 'professor', 'grant', 'simpson', 'killer', 'waste', 'college', 'take', 'recreate', 'deserve', 'stick', 'e.u', 'thump', 'ethical', 'capaz', 'definition', 'pound', 'populism!oh', 'alcee', 'improve', 'disastrous', 'minister', 'protester', 'arab', 'wicked', 'yell', 'nation', 'noise', 'different', 'development', 'americans.but', 'failing', 'insane', 'paycheck', 'shell', 'wretched', 'afraid', 'oligarchic', 'occupy', 'markle', 'survive', 'arm', 'integral', 'motivated', 'interested', 'manner', 'disgust', 'al.com', 'structural', 'stiff', 'solve', 'jews', 'agreement', 'la', 'myanmar', 'frankens', 'crown', 'advisory', 'urgent', 'yeah', 'education', 'ramp', 'preference', 'zimbabwes', 'win', 'parliament', 'joness', 'widen', 'operation', 'realm', 'obvious', 'sacrifice', 'rockefeller', 'have', 'worry', '20', 'mood', 'dwindle', 'weekend', 'size', 'village', 'marriage', 'spin', 'notorious', 'hard', 'worldwide', 'tough', 'proper', 'panther', 'penis', 'owe', 'heston', 'treasury', 'intellectualism', 'second', 'ideal', 'malign', 'gramm', 'reproductive', 'earner', 'significant', 'license', 'heyer', 'satisfied', 'america', 'degraded', 'global', 'il', 'comey', 'chozick', 'portuguese', 'smite', 'force', 'udeid', 'committee', 'plutocrat', 'dowd', 'pilot', 'strike', 'prone', 'fracture', 'marketing', 'unusual', 'toddler', 'jersey', 'currently', 'inner', 'clinic', 'minded', 'racist', 'personal', 'pittsburgh', 'distribution', 'banish', 'credibility', 'phrase', 'hold', 'supporter', 'party', 'intimacy', '16', 'marry', 'dealer', '100', 'installment', '1969.the', 'absolutely', 'profound', 'expand', 'rotten', 'star', 'said.collin', 'wife', 'intellectual', 'prompt', 'soil', 'shed', 'awful', 'lawsuit', 'wow', 'blitzer', 'let', 'conservative', 'birthrate', 'al', 'furious', 'inextricably', 'advantage', 'mnuchin', 'square', 'wet', 'say', 'desperation', 'it.the', 'falsely', 'ideology', 'program', 'multiculturalism', 'bie', 'sitagu', 'farenthold', 'especially', 'illegally', 'h.', 'grandmother', 'exhibit', 'nationalism', 'aim', 'logic', 'effort', 'weapon', 'mosul', 'kurd', 'band', 'demonstrate', 'pan', 'cervical', '1969', 'tap', 'hick', 'canadian', 'book', 'maintain', 'centrist', 'attempt', 'gimmick', 'dolphin', 'deficit.so', 'va', 'perdue', 'princeton', 'daw', 'els', 'europe', 'law', 'loss', 'salesman', 'whatsoever', 'careful', 'tradition', 'pig', '1.3', 'constitute', 'it.trump', 'primarily', 'gleefully', 'sean', 'primary', 'californian', 'space', 'smile', 'date', 'substantive', 'provocation', 'autocrat', 'ekstep', 'particularly', 'rationale', 'island', 'muslim', 'america.neither', 'low', '2011', 'naughty', 'describe', 'partys', 'hearing', 'early', 'gues', 'abstract', 'dehumanize', 'formal', 'warm', 'duke', 'addiction', 'asian', 'rescind', 'body', 'pornographer', 'accompany', 'occur', 'admit', 'kelly', 'coordinate', 'conservatism', 'amiss', 'captain', 'pace', 'sexual', 'cruz', 'public', 'travesty', 'liberty', 'forget', 'facebook', 'sacred', 'indict', 'closing', 'office', 'illusion', 'thankful', 'aware', 'toxic', 'atheism', 'protection', 'classic', 'truman', '50,000', 'relationship', 'electoral', 'sexism', 'join', 'beauty', 'sense', 'ethic', 'hound', 'lewinsky', 'guess', 'farmer', 'opportunity', 'prophet', 'facet', 'stephen', 'matter', 'preparation', 'tank', 'bend', 'structure', 'extremists.it', 'relate', 'rapist', 'matchup', 'simple', 'prevent', 'favorite', '2014', 'trick', 'assumption', 'smart', 'rap', 'insincere', 'doctor', 'emmanuel', 'silence', 'condition', 'right', 'begin', '4,000', 'spread', 'successfully', 'rabin', 'buckley', 'insist', 'text', 'blast', 'freak', 'a.m.', 'haass', 'propose', 'delaware', 'artisan', 'didion', 'undeserved', 'baker', 'single', 'board', 'roem', 'whiplash', 'miller', 'princess', 'course', 'decency', 'unwanted', 'partisanship', 'psychologist', 'critical', 'medical', 'bill.are', 'proportion', 'breed', 'mooch', 'learn', 'understand', 'soul', 'struggle', 'slur', 'recall', 'shrink', 'epstein', 'mario', 'circumstance', 'hoov', 'corker', 'grind', 'marital', 'grid', 'peninsula', 'planned', 'brennan', 'qatar', 'complete', 'virtually', 'obama', 'fox', 'rewrite', 'gaze', 'detail', 'ad', 'depressingly', 'popular', 'pollak', 'box.in', 'idea', 'count', 'astros', 'ordinary', 'mentality', 'argue', 'fiance', 'entertainment', 'son', 'consider', 'adult', 'neo', 'deed', 'affluent', 'unacceptable', 'liability', 'sufficient', 'comedian', 'identity', 'elite', 'comfortable', 'collect', 'oreilly', 'youth', 'assault', 'behavior', 'heartless', 'analyze', 'pure', 'promising', 'guilty', 'india', 'roll', 'hooked', 'enormous', 'simultaneously', 'morning', 'douthat', 'happily', 'pacific', 'aerial', 'music', 'famous', 'land', 'planning', 'elder', 'crime', 'lost.oh', 'notion', 'reluctant', 'dynamic', 'marco', 'worldview', 'place', 'target', 'fraternity', 'priest', 'vicious', 'occupation', 'replace', 'staff', 'saga', 'effectively', 'loyalty', 'kill', 'sphere', 'national', 'scaramucci', 'new', 'surrender', 'debacle', 'steinem', 'direct', 'concerned', 'pyongyang', 'ring', 'passive', 'shine', 'raw', 'accident', 'slaughter', 'combine', 'expansion', 'moon', 'movement', 'benefit', 'appalling', 'cointelpro', 'house', 'wise', 'see', 'smooth', 'eliminate', 'alive', 'tony', 'guard', 'hide', 'cape', 'burmese', 'lean', 'scheme', 'consume', 'harvey', 'politically', 'cnn', 'pruitt', 'sister', 'prison', 'resource', 'iraqi', 'anger', 'income', 'suppose', 'bozo', 'obedience', 'grow', 'monsieur', 'best', 'huge', 'disaster', 'bike', 'swimming', 'revive', 'orrin', 'compete', 'exchange', 'grinstein', 'devos', 'late', 'unveil', 'lindsey', 'high.im', 'authority', 'surface', 'destruction', 'map', 'address', 'highly', 'dreamer', 'modern', 'rick', 'sharknado', 'civil', 'oath', 'potential', 'adam', 'fire', 'directly', 'phil', 'sorry', 'communist', 'devastating', 'keen', 'build', 'racially', 'decline', 'conception', 'rip', 'utter', 'distinctive', 'subsys', 'sound', 'serwer', 'pepfar', 'tuition', 'bob', 'april', 'economy', 'stuff', 'surreal', 'mandate', 'elective', 'david', 'bail', 'female', 'tension', 'ryan', 'university', 'choice', '$', 'narrative', 'indivisible', 'satisfy', 'vital', 'staggering', 'blowout', 'independent', 'source', 'naked', 'dentist', 'ronstadt', 'face', 'married', 'genocide', 'malaria', 'friction', 'thank', 'jean', 'sure', 'dead', '40', 'biased', 'ensure', 'happened.so', 'president.and', 'time.blumenthal', 'majority', 'longtime', 'refer', 'bunker', 'parent', 'sunnis', 'prisoner', 'ukraine', 'flow', 'violence', 'moscow', 'magnitude', 'current', 'macarthur', 'government', 'insider', 'chemical', 'month', 'close', 'portal', 'protestant', 'encouragement', 'gunman', 'shift?well', 'technically', 'intention', 'future.wait', 'xi', 'mitt', 'access', 'enemy', 'train', 'sky', 'apologist', 'craft', 'age', 'noah', 'oslo', 'press', 'diversity', 'ecumenical', 'affinity', 'local', 'class.francis', 'f-15', 'ineffective', 'him.so', 'casualty', 'immigrant', 'mull', 'establish', 'caligulas', '30', 'sensible', 'outburst', 'trillion', 'angry', 'defame', 'afford', 'mini', 'letter', 'anthony', 'quash', 'breathe.the', 'idol', 'silently', 'jeff', 'census', 'confront', 'invest', 'lobbyist', 'roginsky', 'drug', 'jordan', 'mary', 'jesus', 'register', 'dollar', 'los', 'uninsured', 'check', 'veteran', 'president.trump', 'feeble', 'protest', 'american', 'vladimir', 'shooting', 'sanction', 'premium', 'glass', 'page', 'distinguish', 'redeem', 'expose', 'arrival', 'rex', 'dance', 'irish', 'example', 'diplomatic', 'witch', 'newspaper', 'inquire', 'eventually', 'crash', 'girlfriend', 'future', 'unifying', 'deter', 'forgive', 'grin', 'nightmare', 'general', 'venue', 'rely', 'lethal', 'commitment', 'administrator', 'refuse', 'easy', 'nothing.its', 'recognition', 'cultivate', 'faggioli', 'liz', 'touch', 'encourage', 'regional', '2013', '300,000', 'c.e.o.', 'progress', 'tent', 'victory', 'school', 'trade', 'teleprompter', 'mystery', 'culturally', 'traditionally', 'suffer', 'phillip', 'celebrity', 'plan', 'institution', 'consensus', 'conduct', '55', 'reject', 'domestic', 'attorney', 'exactly?.sorry', 'freeman', 'storm', 'dr', 'holocaust', 'again.so', 'human', 'terrorism', 'baby', 'mile', 'egregious', 'christopher', 'obligingly', 'queen', 'hike', 'farage', 'reed', 'display', 'fighting', 'diplomacy', 'satellite', 'discuss', 'wrongdoing', 'douglass', 'torah', 'de', 'word', 'promote', 'inquisition', 'side', 'tim', 'riyadh', 'curve', 'context', 'weak', 'fault', 'isolate', 'obstruction', 'americas', 'rise', 'irony', 'rank', 'exacerbate', 'cancer', 'carefully', 'truly', 'regression', 'ghost', 'horse', 'journalism', 'institute', 'achieve', 'hasting', 'strain', '2012', 'bader', 'juicy', 'push', 'catch', 'region', 'zone', 'hell', 'student', 'fisherman', 'violent', 'reopening', 'impact', 'dormant.there', 'united', 'major', 'thing', 'charm', 'spicer', 'funding', 'quarrel', 'weiner', 'spring', 'l.g.b.t', 'object', 'complacent', 'dj', 'capable', 'ridicule', 'agencys', 'lately', 'hostility', 'chatter', 'lilla', 'east', 'guide', 'merely', 'predatory', 'flynn', 'summer', 'emperor', 'ralph', 'utterly', 'hearken', 'ogre', 'asia', 'believe', 'rural', 'gap', 'pollution', 'intervention', 'joe', 'g.d.p', 'elimination', 'england', 'rationalize', 'conflict', 'block', 'perk', 'accusation', 'enforcement', 'skeptic', 'nut', 'seoul', 'evangelical', 'provider', 'century', '1970', '90', 'assistant', 'illegal', 'tear', 'beneficiary', 'small', 'relation', 'district', 'yangon', 'horror', 'atmosphere', 'transform', 'call', 'bear', 'send', 'operate', 'amen', 'nickname', 'hex', 'environment', 'church', 'deeply', 'swift', 'cook', 'indian', 'unlike', 'host', 'dean', 'affair', 'contact', 'fashion', 'afghan', 'congresss', 'mulvaney', 'power', 'insecurity', 'ivanka', 'constantly', 'complain', 'nuke', 'willey', 'suspicious', 'driverless', 'native', 'standpoint', 'clear', 'neighborhood', 'menz', 'marie', 'pleasure', 'equality', 'hair', 'carbone', 'entire', 'desperately', 'root', 'core', 'migrant', 'financial', 'elne', 'york', 'slow', 'counsel', 'apple', 'decouple', 'young', 'desperate', 'jewish', 'hours.when', 'ideologue', 'resolution', 'mistake', 'victim', '2027', 'liar', 'military', 'abuser', 'brown', 'sales', 'february', 'identitarian', '1.not', 'invent', 'hug', 'embarrassment', 'television', 'degree', 'expensive', 'maine', 'oppose', 'brito', 'user', 'prayer', 'tall.i', 'trot', 'charge', 'society', 'o.k', 'radical', 'aid', 'headline', 'carolina', 'express', 'ability', 'branch', 'regret', 'crowd', 'pay', 'fake', 'vote', 'serve', 'm.b.s.s', 't', 'delhi', 'bennett', 'geographic', 'chance', 'orthodox', 'stunning', 'disagree', 'kushner', 'opt', 'revenue', 'watch', 'fist', 'emmys', 'insult', 'facts.g.o.p', 'stage', 'inherently', 'movement.it', 'communion', 'justice', 'mess', 'industry', 'reciprocity', 'arrive', '1994', 'stardom', 'blair', 'perceive', 'skeptical', '3', 'chesky', 'horrify', 'joke', 'abandon', 'go', 'accord', 'cover', 'freedman', 'million', 'memo', 'administrative', 'meaning', 'channel', 'televangelist', 'unresolved', 'friend', 'malone', 'advertising', 'role', 'read', 'arabia', 'theory', 'action', 'make', 'strange', 'deny', 'few', 'convention', 'disappear', 'olson', 'advance', 'range', 'paul', 'wright', 'liberalism', 'murillo', 'motel', 'foot', 'uncomfortable', 'depravity', 'suggestion', 'brave', 'husband', 'manus', 'hypocrite', 'tariff', 'option', 'contest', 'prize', 'medicaid', 'trumpworld', 'slavery', 'truthful', 'moral', 'strongman', '300', 'explode', 'bitch', 'head', 'business', 'ultimately', 'treat', 'well', 'meritocratic', 'finding', 'west', 'dozen', 'device', 'merkel', 'socialist', 'persuasion', 'sarah', 'maslow', 'leeann', 'sustainable', 'immortal', 'san', 'jet', 'owner', 'arafat', 'steal', 'fair', 'project', 'hope', 'website', 'gift', 'inappropriate', 'annual', 'monk', 'similarly', 'previous', 'finally', 'wish', 'rohingya', 'deportation', 'protect', 'blueprint', 'courage', 'seriously', 'finkel', 'airline', 'promptly', 'clearly', 'bother', 'analyst', 'chain', 'fix', 'good', 'taxation', 'edgar', 'grip', 'permanent.when', 'plastic', 'entirely', 'organizations.the', 'live', 'ireland', 'possible.first', 'mainstream', 'bin', 'convict', 'cellphone', 'understanding', 'ease', 'congressional', 'ruling', 'cheap', 'sexually', 'claim', 'kremlin', 'strive', 'sleep', 'sheer', 'resentment', 'amendment', 'themselves.even', 'soar', 'kiss', 'category', 'merger', 'point', 'w.', 'eagle', 'attract', 'harm', 'priority', 'specialize', 'corporate', 'chart', 'sale', 'franci', 'armed', 'expenditure', 'crew', 'historian', 'song', 'cuban', 'collinss', 'flood', 'create', 'nonprofit', 'bar', 'route', 'section', 'alien', 'hyperbole', 'shared', 'willingness', 'kolli', 'opening', 'blandishment', 'gossip', 'briefing', 'honorary', 'completely', 'tour', 'empowerment', 'havoc', 'caricature', 'movie', 'image', 'trumps', 'quality', 'junior', 'dirty', 'underground', 'explicit', 'openly', 'rod', 'change', 'remove', 'system', 'epic', 'story', 'humanity', 'write', 'preventable', 'banker', 'pierce', 'roughly', 'abroad', 'dear', 'pour', 'practically', 'wage', 'problem', 'opinion', 'creep', 'inauguration', 'union', 'pregnant', 'massive', 'practical', 'oxycontin', 'explosion', 'grand', 'cohen', 'abusive', 'sarandon', 'spend', 'm.b.s', 'rake', 'unify', 'appeal', 'biblical', 'miraclefeet', 'legislature', 'bisexual', 'budget', 'whistle', 'dropout', 'that.but', 'communism', 'thomas', 'dominance', 'wide', 'rarely', 'anniversary', 'airbnb', 'attachment', 'dotard', 'h.i.v./aid', 'impulse', 'bellow', 'january', 'decriminalization', 'angel', 'fuel', 'goldman', 'unfair', 'quietly', 'attack', 'warhead', 'berlin', 'christianity', 'round', 'swallow', 'fugitive', 'addition', 'lot', 'rapidly', 'trump.it', 'hoover', 'explore', 'classified', 'papal', 'maricopa', 'misspoke', 'judge', 'punish', 'florida', 'discourage', 'zionist', 'savvy', 'systematically', 'exit', 'deflect', 'palace', 'golf', 'green', 'pass', 'rifle', 'deputy', 'collaborator', 'animal', 'spencer', 'design', 'supremacy', 'induce', 'teach', 'regard', 'lower', 'corner.actually', 'topple', 'foul', 'fund', 'pistol', 'indicate', 'undercover', 'wealth', 'inside', 'available', 'marginal', 'affect', 'knowledge', 'praise', 'array', 'mockery', 'gender', 'manhattan', 'myong', 'largely', 'class.nor', 'minute', 'taliban', 'competition', 'resistance', 'shred', 'insistence', 'spadaro', '2020', 'explain', 'paper', 'nose', 'wild', 'wall', 'basically', 'pluralism', 'retain', 'cain', 'alleged', 'essay', 'brace', 'event', 'marxism', 'gather', 'soldier', 'comment', 'declaration', 'authentic', 'bid', '44', 'publicly', 'instead', 'clean', 'bull', 'usual', 'dissolve', '35', 'contractor', 'purchase', 'hasnt', 'genius', 'bury', 'expect', 'propublica', 'clue', 'bracciale', 'coach', '1979', 'attend', 'bof', 'longer', 'grass', 'astonishing', 'gain', 'break', 'explanation', 'statement', '38', 'aircraft', 'crackup', 'population', 'hitler', 'jesuit', 'foster', 'lie', 'probably', 'associated', 'carry', 'foreign', 'thousand', 'simply', 'bone', 'mention', '1960', 'chaotic', 'mattis', 'sympathizer', 'actively', 'freeze', 'f.b.i.it', 'gladwell', 'staffer', 'reporter', 'stop', 'connection', 'organization', 'reaction', 'nuclear', 'tea', 'anonymous', 'incredibly', 'method', 'game', 'division', 'implementation', 'dem', 'bushs', 'accountability', 'advanced', 'voter', 'niger', 'projection', 'theological', 'foundation', 'constituency', 'maternity', 'acceptable', 'estimate', 'tax', 'mislead', 'communication', 'fill', 'not', 'a.i', 'citizenship', 'anchor', 'joseph', 'decorate', 'secret', 'companys', 'cautionary', 'august', 'rhetoric', 'legal', 'wreck', 'planner', 'distrust', 'uniquely', 'airport', 'prescription', 'republican', 'rhetorical', 'appetizing', 'saudi', 'habit', 'assume', 'weinstein', 'co', 'drone', 'reportedly', 'justify', 'scale.and', 'wildly', 'broadly', 'ally', 'hook', 'prescribe', 'portman', 'effective', 'invite', 'alternative', 'broaddrick', 'backpage', 'caddishness', 'fare', 'style', 'flesh', 'fully', 'shore', 'collective', 'stevenson', 'careless', 'bloc', 'politico', 'con', 'task', 'buffoon', 'thrive', 'impress', 'statistic', 'leak', 'joy', 'instrument', 'gold', 'mccain', 'offend', 'audacious', 'earn', 'manager', 'sincerity', 'unlock', 'g.o.p', 'feminist', 'permanent', 'inflict', 'agree', 'choe', 'harsh', 'michelle', 'troll', 'anita', 'dossier', 'loophole', 'bigot', 'accountable', '2008', 'bracket', 'frame', 'policy', 'producer', 'shut', 'assert', '60', 'lordy', 'mirror', 'forfeit', 'seize', 'southern', 'detailed', 'harding', 'thaler', 'season', 'hostage', 'prosperity', 'publish', 'note', 'pick', 'robert', 'professional', 'regular', 'cousin', 'tyranny', 'study', 'trafficker', 'fifth', 'quiet', 'snake', 'price', 'jr', 'principled', 'firearms.the', 'uranium', 'area', 'battle', 'cynic', 'warrior', 'reverence', 'undemocratic', 'evertz', 'statue', 'entitlement', 'egypt', 'original', 'fruit', 'rage', 'denial', 'persian', 'susan', 'retake', 'authenticity', 'presence', 'parenting', 'wave', 'rabbis', 'sheriff', 'appreciate', 'wreckage', 'halt', 'hef', 'shock', 'businessman', 'witness', 'regime', 'rand', 'mortgage', 'flynns', 'nov', 'oval', 'hillarys', 'twin', 'on.there', 'sight', 'remarkably', 'unfairly', '59,000', 'chris', 'frankly', 'skill', 'recently', 'gore', 'midterm', 'level', 'room', 'generation', 'jerrold', 'unlikely', 'shiite', 'craig', 'leverage', 'gov', 'sharply', 'psychopath', 'police.the', 'pull', 'floor', 'gathering', 'cotton', 'kristof', 'rome', 'n.f.l', 'acces', 'emerge', 'impede', 'monarchy', 'airbnbs', 'description', 'evening', 'kook', 'boston', 'pillage', 'mixed', 'investigation.but', 'appear', 'withdraw', 'newton', 'session', 'fear', 'confuse', 'ni', 'repeal', 'sign', 'energy', 'stalking', 'opioid', 'impolite', 'terrorism.the', 'strip', 'partially', 'person', 'burst', 'prosecutor', 'gist', '22', 'consciousness', 'athlete', 'legend', 'oo', 'favor', 'abortion', 'super', 'excellent', 'plus', 'catholic', 'deficit', 'prostitution', 'predictable', 'repeat', 'lead', 'insight', 'iranian', 'follow', 'kid', 'gun', 'chuck', 'infuse', 'closer', 'being', 'passenger', 'pretend', 'track', 'feel', 'oh', 'cat', 'inquiry', 'gene', 'guy', 'official', 'patriarchy', 'pressure', 'history', 'shame', 'behalf', 'buy', 'mika', 'confederate', 'honest', 'easily', 'liberate', 'politics', 'depend', 'withdrawal', 'afghanistan', 'arise', 'curiosity', 'wag', 'gillespie', 'tom', 'gentleman', 'chocolate', 'phoenix', 'apart', 'rough', 'superiority', 'j.', 'material', 'libertarian', 'everybody', 'deserving', 'stabilize', 'permanently', 'plunge', 'interdependent', '2', 'multiple', 'authoritarian', 'numb', 'reopen', 'stranger', 'nonchalance', 'underway', 'semite', 'postwar', 'radio', 'name', 'normal', 'hero', 'legitimate', 'william', 'chinese', 'obsession', 'jim', 'hammer', 'sum', 'visit', 'racism', 'speak', 'compel', 'frequent', 'richard', 'bannon', 'malnutrition', 'dallas', 'counterterrorism', 'trumpism', 'perspective', 'pride', 'give', 'regularly', 'fan', 'supposedly', 'publication', 'exile', 'muster', 'brexit', 'antimissile', 'delegation', 'comeys', 'physical', 'discredit', 'fraud', 'funny', 'exist', 'implication', 'jared', 'equal', 'seven', 'exemplary', 'unrelated', 'find', 'resist', 'assure', 'molest', 'disturbing', 'passion', 'social', 'working', 'headquarters', 'outrage', 'ecclesiastical', 'bureau', 'white', 'beautiful', 'incomparably', 'uncertain', 'reputation', 'add', 'able', 'jail', 'hahm', 'testimony', 'bigoted', 'george', 'reflect', 'boast', 'observe', 'inherit', 'end', 'widely', 'dirt', 'focus', 'reform', 'certainly', 'roe', 'overall', 'muscle', '12-nation', 'boot', 'greed', 'thin', 'wolf', 'base', 'instagram', 'toll', 'restrain', 'attention', 'rice', 'secular', 'apparently', 'separatism', 'odd', 'razak', 'luther', 'peace', 'galling', 'influential', 'judgment', 'harshly', 'einstein', 'nationalist', 'poll', 'opponent', 'humor', 'fellow', 'britain', 'troubled', 'c.e.o.s', 'one', '63', 'backdrop', 'investigator', 'patriot', 'reveal', 'attitude', 'media', 'leave', 'hot', 'honestly', 'guarantee', 'finish', 'award', 'zero', 'procedure', 'laura', 'armor', 'spirit', 'ideologically', 'rakhine', 'factor', 'credit', 'beyer', 'hatch', 'nearly', 'review', 'deception', 'shift', 'injustice', 'whiteness', 'agonizing', 'classify', 'natural', 'collaboration', 'door', 'timess', 'immediate', '7', 'panic', 'bossie', 'imperial', 'nancy', 'wyden', 'scrap', 'chronic', 'scout', 'association', 'battery', 'retaliatory', 'chef', 'connect', 'escalate', 'civilization', 'inflation', 'lower-', 'crusade', 'soft', 'bully', 'romney', 'rail', 'intimidation', 'extremism', 'weave', 'controversy', '80', 'scarborough', 'assertion', 'holder', 'settlement', 'atop', 'disapprove', 'throne', 'thinking', 'environmental', 'switch', 'yong', '13-year', 'secretary', 'non', 'mock', 'earlier', 'surveillance', 'religion', 'measure', 'threat', 'donald', 'medicare', 'parade', 'oil', 'politic', 'promise', 'air', 'duty', 'alongside', 'necessarily', 'collapse', 'upper', 'disability', 'decision', 'incoherence', 'allen', 'plutocracy', 'articulate', 'daily', '18', 'philippine', 'frustrated', 'hayess', 'boat', 'steve', 'kor', 'antitrust', 'digital', 'pence', 'falsehood', 'sayadaw', 'rating', 'g.o.p.s', 'army', 'computer', 'false', 'surround', 'negro', '4', 'discrimination', 'debate', 'planes.representative', 'cloud', 'ministry', 'matt', 'theresa', 'published.the', 'klan', 'schumer', 'scott', 'cockpit', 'enact', '1', 'risk', 'transition', 'latino', 'hail', 'murder', 'disqualify', 'ndebele', 'tonight', 'vision', 'unclear', 'prove', 'shark', 'maverick', 'legislative', 'tangle', 'undermine', 'mobility', 'enthusiast', 'confidence', 'sander', 'speaker', 'jong', 'difficult', 'flanagan', 'list', 'flawed', 'slide', 'chinas', 'handling', 'ian', 'feeling', 'earth', 'despicable', 'extra', 'founder', 'vu', 'rattlesnake', 'certain', 'twitter', 'conversely', 'suburb', 'usually', 'blockade', 'message', 'reading', 'year', 'troop', 'racists.the', 'mitch', 'hagel', 'minor', 'revival', 'performance', 'column', 'may', 'reaper', 'think', 'sweep', '26', 'anxiety', 'trickle', 'clueless', '2018', 'void', 'driver', 'elderly', 'city', 'wing', 'ill', 'stock', 'investor', 'appoint', 'humiliation', 'language', 'misdirect', 'bombing', 'paragraph', 'indifferent', 'loud', 'lynch', 'firing', 'service', 'preclude', 'miraculously', 'mandalay', 'common', 'familiar', '2017', 'profit', 'neutralize', 'countrys', 'alt', 'maybe', 'blue', 'international', 'bond', 'factory', 'republic', 'concert', 'kind', 'news', 'irresponsibility', 'dare', 'past', 'crap', 'wonder', 'hefner', 'arpaio', 'issue.not', 'barr', 'kirsten', 'trough', 'lifetime', 'conflate', 'phantom', 'swiftly', 'consistent', 'raise', 'd.c', 'middle', 'cheney', 'camp', 'war', '75,000', 'asher', 'partnership', 'hotel', 'ready', 'sector', 'plate', 'divide', 'mind', 'jettison', 'heavily', 'sip', 'reminder', 'cause', 'accuser', 'steven', 'nationwide', '1999', '1955', 'additional', 'exxon', 'life', 'doctrine', 'cool', 'art', 'combat', 'expire.take', 'nutty', 'develop', 'meaningless', 'johnson', 'men', 'start', 'proposal', 'electricity', 'pastor', 'dishonesty', 'fiction', 'interracial', 'aside', 'legendary', 'delegate', 'independence', 'syrian', 'expense.for', '12', 'pretty', 'righteous', 'bask', 'lecherous', 'stark', 'avoid', 'allude', 'beirut', 'tempt', '1st', 'racial', 'return', 'baseball', 'infinite', 'curry', 'advise', 'intraparty', 'espn', 'damon', 'suicide', 'doug', 'jam', 'saddam', 'solemn', 'jackson', 'imperialist', 'gop', 'plea', 'black', 'film', 'posture', 'firearm', 'doubtful', 'salt', 'spokeswoman', 'ted', 'tend', 'franciss', 'important', 'angele', 'specific', 'valley', 'disreputable', 'furthermore', 'nothing.there', 'half', 'resident', 'mr', 'callous', 'billion', 'try', 'rest', 'incessantly', 'standard', 'era', 'surely', 'pile', 'football', 'figure', 'tennessee', 'expos', 'cromwell', 'tiny', 'california', 'deterrence', 'boss', 'terrible', 'enter', 'lying', 'code', 'breathe', 'precisely', 'jone', 'fracas', 'happen', 'sudan', 'enjoy', 'remark', 'rev', 'prey', 'anxiously', 'draft', 'cure', 'coalition', 'element', 'ethiopia', 'chilling.the', 'umpire', 'partisan', 'unhappy', 'sandwich', 'mar', 'criminal', 'link', 'attention.the', 'internet', 'cushion', 'window', 'identify', 'bluntly', 'anemic', 'marginalize', 'trumpet', 'erode', 'siege', 'benghazi', 'reagan', 'feed', 'conyer', 'lay', 'involf', 'thursday', 'gospel', 'perry', 'calculation', 'warn', 'portugal', 'settle', '2016', 'ignorant', 'evasion', 'greek', 'climate', 'sweeping', 'career', 'line', 'airstrike', 'suggest', 'cultural', 'player', 'exercise', 'secularize', 'years.or', 'bush', 'fight', 'haunt', 'look', 'outside', 'comparison', 'barrel', 'putin', 'possibility', 'clinton', 'crack', 'wisdom', 'improvement', 'undercut', 'suddenly', 'smell', 'stephenson', 'iron', 'boy', 'psychological', 'receive', 'deep', 'extraordinary', 'success', 'autocratic', 'title', 'status', 'day', 'aung', 'huckabee', 'attendee', 'downplay', 'manufacturing', 'urge', 'god', 'scorekeeper.how', 'employer', 'morgan', '58', 'ask', 'healthy', 'dsouza', 'stay', 'idolatry', 'reward', 'commedia', 'political', 'tragedy', 'strategy', 'bathroom', 'strategist', 'usage', 'intense', 'billionaire', 'resignation', 'homicide', 'mo', 'joan', 'tower', 'royal', 'capability', 'ground', 'contraceptive', 'july', 'provide', 'beast', 'dictate', 'humanitarian', 'budget.thus', 'x', 'constant', 'june', 'offensive', 'shutdown', 'function', 'safe', 'elitist', 'exploitation', 'efficient', 'ancient', 'defund', 'cross', 'tie', 'perpetual', 'expire', 'heal', 'counter', '2016.the', 'c.e.o', 'immigration', 'republicans', 'mexican', 'griffon', 'google', 'estate', 'socioeconomic', 'embody', 'trafficking', 'criticism', 'conclude', 'powerfully', 'treaty', 'amazing', 'experience', 'straightforward', 'pose', 'previously', 'nonpartisan', 'street', 'flip', 'lunch', 'rubio', 'miss', 'quarterback', 'comeback', 'prepare', 'sentimental', 'likewise', 'danger', 'accurate', 'trump.yet', 'millennial', 'dark', 'warning', 'c.i.a', 'harvard', 'median', 'experiment', 'approval', 'misdeed', 'sue', 'lee', 'therapy', 'hour', 'pledge', 'blame', 'better', 'fortune', 'havent', 'freedom', 'actress', 'john', 'slave', 'campaign', 'increasingly', 'enlarge', 'high', 'raiser', 'roman', 'summon', 'malicious', 'red', 'weakness', 'complicated', 'transgender', 'tillerson', 'van', 'charlottesville', 'embrace', 'forecast', 'away', 'solar', 'libertinism', 'voller', 'inform', 'purdue', 'hostile', 'universitys', 'moderate', 'japan', 'want', 'county', 'negotiate', 'manufacture', 'lack', 'heavy', 'editor', 'digitize', 'ten', 'socially', 'controversial', 'dysfunction', 'clubfoot', 'brand', 'slam', 'collin', 'die', 'incitatus', 'stake', 'graduate', 'teen', 'transportation', 'junk', 'repression', 'pair', 'concession', 'opposite', 'silencer', 'defend', 'linger', 'essentially', 'georgia', 'worried', 'swing', 'handler', 'carter', 'demographic', 'inhabit', 'matters.as', 'interaction', 'joint', 'pakistan', 'shoot', 'protector', 'confess', 'refugee', 'rebuild', 'tweeden', 'embassy', 'whiner', 'elect', 'culture', 'field', 'prevalent', 'dreadful', 'methadone', 'melania', 'roy', 'sort', 'monica', 'impeachment', 'trash', 'engage', 'failure', 'carpet', 'versus', 'hire', 'net', 'seasoning', 'minimum', 'confine', 'evoke', 'predecessor', 'wound', 'f.b.i.s', 'use', 'mission', 'property', 'bunch', 'catastrophic', 'receipt', 'texas', 'fact', 'beggar', 'brac', 'painful', 'ronald', 'did.at', 'rebuke', 'bible', 'dwarfed', 'buchanan', 'african', 'subordinate', 'pit', 'mass', 'fort', 'plenty', 'form', 'foreignpolicy.org', 'ed', 'deliver', 'cable', 'lisbon', 'skin', 'artist', 'virginia', 'empire', 'community', 'occult', 'painkiller', 'get', 'leadership', 'button', 'leaker', 'friendly', 'isis', 'slope', 'spray', 'north', 'cut', 'cruelty', 'sink', 'vietnam', 'tarmac', 'maul', 'videotape', 'them.the', '64,000', 'decade', 'reconnect', 'thanksgiving', 'hugh', 'vatican', 'man', 'liberal', 'holiday', 'safer.liz', 'advocate', 'state', 'election', 'voice', 'concussion', 'case', 'suite', 'redemption', 'jacobin', 'carman', 'democrat', 'arrest', 'notice', 'european', 'obsess', 'trump.trump', 'mayor', 'expediency.the', 'harry', 'obamacare', 'productivity', 'importation', 'mall', 'savor', 'fine', 'drink', 'hop', 'parish', 'adviser', 'peter', 'alarm', 'oblivious', '19th', 'tweet', 'referendum', 'consequence', 'volume', 'mental', 'hunt', 'prejudice', 'allegiance', 'suu', 'leap', 'nick', 'unfit', 'institutional', 'galore', 'orientation', 'productive', 'semitism', 'alcohol', 'order', 'b.i.e.s', 'impetuous', 'justification', 'shortly', 'passage', 'scale', 'sponsor', 'h.i.v', 'plain', 'moore', 'hospital', 'appropriate', 'sunday', 'condemn', 'brush', 'somewhere', 'ball', 'museum', 'brain', 'taxpayer', 'industrial', 'regardless', 'strong', 'fundamental', 'right?actually', 'insensitive', 'pusher', 'people', '67', 'shape', 'finance', 'crucially', 'effect', 'pew', 'campus', 'pundit', 'dad', 'light', 'honor', 'anew', 'glory', 'australia', 'continue', 'vialard', 'taunt', 'metaphysical', 'fun', 'tape', 'bndchen', 'approve', 'buddhist', 'department', 'fit', 'arsenal', 'technology', 'u-2s', 'yesterday', 'absence', 'flaw', 'mexico', 'pack', 'lesson', 'hundred', 'unpopular', 'throw', 'norm'}\n",
      "4461\n"
     ]
    }
   ],
   "source": [
    "# return most common words for writers\n",
    "\n",
    "common_words = []\n",
    "for i, row in df_writer_combined_text.iterrows():\n",
    "    baggedwords = bag_of_words(row['combined_text_tokenized'])\n",
    "    common_words.append(baggedwords)\n",
    "\n",
    "flat_list=[]\n",
    "for sublist in common_words:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "        \n",
    "\n",
    "words_in_articles = set(flat_list)\n",
    "print(words_in_articles)\n",
    "print(len(words_in_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n",
      "Processing row 5500\n",
      "Processing row 6000\n",
      "Processing row 6500\n",
      "Processing row 7000\n",
      "Processing row 7500\n",
      "Processing row 8000\n",
      "Processing row 8500\n",
      "Series([], dtype: float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operative</th>\n",
       "      <th>justice.but</th>\n",
       "      <th>shrug</th>\n",
       "      <th>psalm</th>\n",
       "      <th>bad</th>\n",
       "      <th>police</th>\n",
       "      <th>ko</th>\n",
       "      <th>outrageous</th>\n",
       "      <th>product</th>\n",
       "      <th>abraham</th>\n",
       "      <th>...</th>\n",
       "      <th>flaw</th>\n",
       "      <th>mexico</th>\n",
       "      <th>pack</th>\n",
       "      <th>lesson</th>\n",
       "      <th>hundred</th>\n",
       "      <th>unpopular</th>\n",
       "      <th>throw</th>\n",
       "      <th>norm</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(steve, bannon, may, no, longer, be, physicall...</td>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(leadership, ,, breitbart, has, given, favorab...</td>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(and, spencer, loves, it.yes, ,, that, richard...</td>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(that, was, the, same, protest, about, which, ...</td>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(i, do, nt, think, it, has, done, this, delibe...</td>\n",
       "      <td>CHARLES M. BLOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  operative justice.but shrug psalm bad police ko outrageous product abraham  \\\n",
       "0         0           0     0     0   0      0  0          0       0       0   \n",
       "1         0           0     0     0   0      0  0          0       0       0   \n",
       "2         0           0     0     0   0      0  0          0       0       0   \n",
       "3         0           0     0     0   0      0  0          0       0       0   \n",
       "4         0           0     0     0   0      0  0          0       0       0   \n",
       "\n",
       "        ...        flaw mexico pack lesson hundred unpopular throw norm  \\\n",
       "0       ...           0      0    0      0       0         0     0    0   \n",
       "1       ...           0      0    0      0       0         0     0    0   \n",
       "2       ...           0      0    0      0       0         0     0    0   \n",
       "3       ...           0      0    0      0       0         0     0    0   \n",
       "4       ...           0      0    0      0       0         0     0    0   \n",
       "\n",
       "                                       text_sentence      text_source  \n",
       "0  (steve, bannon, may, no, longer, be, physicall...  CHARLES M. BLOW  \n",
       "1  (leadership, ,, breitbart, has, given, favorab...  CHARLES M. BLOW  \n",
       "2  (and, spencer, loves, it.yes, ,, that, richard...  CHARLES M. BLOW  \n",
       "3  (that, was, the, same, protest, about, which, ...  CHARLES M. BLOW  \n",
       "4  (i, do, nt, think, it, has, done, this, delibe...  CHARLES M. BLOW  \n",
       "\n",
       "[5 rows x 4463 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, words_in_articles)\n",
    "\n",
    "print(word_counts.sum())\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 19740\n",
      "307\n"
     ]
    }
   ],
   "source": [
    "# create features with tf-idf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "ft_list=[]\n",
    "for i,row in op_ed_articles.iterrows():\n",
    "    article=row['full_text']\n",
    "    ft_list.append(article)\n",
    "#print(ft_list)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.6, # drop words that occur in more than half the articles\n",
    "                             stop_words='english', \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "#norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "#Applying the vectorizer\n",
    "full_text_tfidf=vectorizer.fit_transform(ft_list)\n",
    "print(\"Number of features: %d\" % full_text_tfidf.get_shape()[1])\n",
    "\n",
    "\n",
    "# #Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = full_text_tfidf.tocsr()\n",
    "\n",
    "# #number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per article\n",
    "tfidf_byarticle = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each article, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_byarticle[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "    \n",
    " #Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "#print('Original sentence:', op_ed_articles['full_text'][2])\n",
    "#print('Tf_idf vector:', tfidf_byarticle[2])\n",
    "print(len(tfidf_byarticle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 82.0058129488\n"
     ]
    }
   ],
   "source": [
    "# reduce number of words in bow\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space from 1081 to 100.\n",
    "svd= TruncatedSVD(1000)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'],axis=1))\n",
    "X_train_lsa_bow = lsa.fit_transform(X)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the features to fit supervised learning models for each feature set to predict the category outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for BoW dataset\n",
    "Y = word_counts['text_source']\n",
    "#X = np.array(word_counts.drop(['text_sentence','text_source'],axis=1))\n",
    "X = X_train_lsa_bow\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X, \n",
    "                                                    Y,stratify=Y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.583207944628\n",
      "\n",
      "Test set score: 0.312274368231\n"
     ]
    }
   ],
   "source": [
    "# using BoW dataset\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "# Fit our model to the data.\n",
    "bnb.fit(X_train_bow, y_train_bow)\n",
    "y_pred = bnb.predict(X_train_bow)\n",
    "\n",
    "print('Training set score:', bnb.score(X_train_bow, y_train_bow))\n",
    "print('\\nTest set score:', bnb.score(X_test_bow, y_test_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.978260869565\n",
      "\n",
      "Test set score: 0.493506493506\n"
     ]
    }
   ],
   "source": [
    "# using tf-idf dataset\n",
    "# Fit our model to the data.\n",
    "bnb.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred = bnb.predict(X_train_tfidf)\n",
    "\n",
    "print('Training set score:', bnb.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTest set score:', bnb.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.605025579296\n",
      "\n",
      "Test set score: 0.43321299639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# using BoW dataset\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print('Training set score:', lr.score(X_train_bow, y_train_bow))\n",
    "print('\\nTest set score:', lr.score(X_test_bow, y_test_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.934782608696\n",
      "\n",
      "Test set score: 0.571428571429\n"
     ]
    }
   ],
   "source": [
    "# using tf-idf dataset\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('Training set score:', lr.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTest set score:', lr.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick one of the models and try to increase accuracy by at least 5 percentage points\n",
    "I chose to work with the logistic regression model and the tf-idf dataset since it appears to have the strongest performance on the test dataset - although it obviously has a problem with overfitting\n",
    "1. Starting Values (training/test): .93/.57\n",
    "2. Added word count and unique word count as features: .88/.58\n",
    "3. Reduced the number of features from ~2000 to 150: .88/.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 20111\n",
      "Tf_idf vector: {'federal': 0.030719553064942735, 'investigation': 0.28823770036879054, 'counterterrorism': 0.05344914344408784, 'real': 0.022574254958545651, 'law': 0.027172893638431898, 'justice': 0.030286563288530473, 'pointed': 0.035331192708502809, 'history': 0.023440581273114932, 'entire': 0.034998141785804369, 'attorney': 0.12125455031623039, 'general': 0.060152791002577762, 'chief': 0.030286563288530473, 'news': 0.022678828728163757, 'inevitably': 0.042833333251246039, 'meeting': 0.17028195732978368, 'motivated': 0.050335473793989262, 'connection': 0.040973346200979394, 'attention': 0.027999501372805085, 'possibility': 0.033471205658236171, 'decided': 0.034998141785804369, 'conspiracy': 0.084354349447836693, 'away': 0.023901216788586321, 'supporters': 0.037578536044032107, 'hillary': 0.028348670393727394, 'clinton': 0.028348670393727394, 'little': 0.046434825044399018, 'times': 0.063076294381837095, 'need': 0.044941363820407872, 'far': 0.021299453715999582, 'accounts': 0.04353185308884204, 'come': 0.021392358157309842, 'appear': 0.042177174723918347, 'wrong': 0.029274302615351157, 'reason': 0.02870948050311483, 'especially': 0.029469322323203227, 'normal': 0.14269927370142663, 'appointment': 0.16034743033226351, 'director': 0.072059425092197635, 'special': 0.032916042896000239, 'counsel': 0.1284999997537381, 'investigate': 0.095840647962973383, 'sitting': 0.040418183438743469, 'presidents': 0.081999725311767732, 'associates': 0.16034743033226351, 'colluded': 0.10356144848716169, 'kremlin': 0.22540338293387668, 'office': 0.091137690983148972, 'powerful': 0.03436129334559182, 'reaffirmation': 0.065339754879475714, 'rule': 0.033759844122403841, 'official': 0.034675034181175117, 'appointed': 0.049060672551443189, 'prosecutor': 0.049060672551443189, 'demonstrated': 0.04353185308884204, 'independence': 0.04688875322119225, 'informing': 0.06095128398683107, 'advance': 0.040418183438743469, 'believed': 0.085666666502492078, 'reassured': 0.06095128398683107, 'credible': 0.044278583700837613, 'partisan': 0.037578536044032107, 'myth': 0.050335473793989262, 'feel': 0.028527572003355584, 'confident': 0.049060672551443189, 'fall': 0.034675034181175117, 'prey': 0.055422464524229921, 'pressures': 0.06095128398683107, 'living': 0.030942721815858155, 'inaugurated': 0.06095128398683107, 'january': 0.042177174723918347, 'set': 0.029469322323203227, 'making': 0.045782114230616421, 'mockery': 0.05344914344408784, 'oath': 0.10689828688817568, 'presidency': 0.028172677882613434, 'robert': 0.031884472135705798, 'mueller': 0.19693306339224509, 'kaper': 0.12190256797366214, 'classic': 0.047920323981486691, 'late': 0.030719553064942735, 'action': 0.032916042896000239, 'taken': 0.031403357331329547, 'person': 0.027333241770589246, 'chosen': 0.045947002901344611, 'deputy': 0.044278583700837613, 'rod': 0.050335473793989262, 'rosenstein': 0.28918807168366245, 'united': 0.022165780030568859, 'states': 0.020935611020165553, 'rosensteins': 0.065339754879475714, 'boss': 0.04353185308884204, 'jeff': 0.033759844122403841, 'sessions': 0.077810995748145539, 'recused': 0.057837614336732492, 'russia': 0.10805954575473958, 'sessionss': 0.055422464524229921, 'recusal': 0.057837614336732492, 'meaningful': 0.04688875322119225, 'took': 0.028172677882613434, 'demanded': 0.049060672551443189, 'james': 0.032916042896000239, 'comey': 0.29524022306742842, 'fired': 0.071349636850713313, 'tainted': 0.06095128398683107, 'obeyed': 0.065339754879475714, 'orders': 0.045080676586775337, 'gin': 0.065339754879475714, 'memo': 0.04688875322119225, 'dismissed': 0.042177174723918347, 'clintons': 0.036396639242796298, 'emails': 0.041558532008699967, 'fact': 0.023107530350416492, 'tried': 0.029469322323203227, 'responsibility': 0.039386612678449021, 'comeys': 0.050335473793989262, 'dismissal': 0.055422464524229921, 'blurted': 0.065339754879475714, 'inquiry': 0.10067094758797852, 'affair': 0.049060672551443189, 'needs': 0.029274302615351157, 'investigated': 0.057837614336732492, 'murky': 0.055422464524229921, 'business': 0.028348670393727394, 'kept': 0.036029712546098817, 'alive': 0.050335473793989262, 'large': 0.03264878731851837, 'measure': 0.037578536044032107, 'actions': 0.12653152417175506, 'russian': 0.10127953236721154, 'foreign': 0.028348670393727394, 'minister': 0.036396639242796298, 'ambassador': 0.040418183438743469, 'shortly': 0.045947002901344611, 'sharing': 0.04688875322119225, 'highly': 0.036396639242796298, 'classified': 0.06095128398683107, 'information': 0.035331192708502809, 'hard': 0.027496001243061143, 'imagine': 0.032916042896000239, 'allow': 0.033759844122403841, 'reputation': 0.088557167401675227, 'ruined': 0.055422464524229921, 'putting': 0.037578536044032107, 'thumb': 0.057837614336732492, 'scale': 0.035331192708502809, 'expected': 0.04688875322119225, 'sacrifice': 0.04688875322119225, 'thrusting': 0.06095128398683107, 'middle': 0.024885831722706506, 'presidential': 0.031170589199778592, 'election': 0.048764663185925136, 'mislead': 0.065339754879475714, 'congress': 0.024885831722706506, 'reasons': 0.035674818425356657, 'announcing': 0.050335473793989262, 'days': 0.025687924608644233, 'reopening': 0.06095128398683107, 'email': 0.045947002901344611, 'moved': 0.040973346200979394, 'strong': 0.031403357331329547, 'believe': 0.024885831722706506, 'firing': 0.041558532008699967, 'grave': 0.047920323981486691, 'abuse': 0.037170061116055308, 'aimed': 0.039890112808192962, 'thwarting': 0.065339754879475714, 'harm': 0.042177174723918347, 'legal': 0.036029712546098817, 'experts': 0.038003033626240898, 'violation': 0.06095128398683107, 'possibly': 0.078773225356898041, 'obstruction': 0.057837614336732492, 'urgent': 0.049060672551443189, 'issues': 0.031884472135705798, 'addressed': 0.04688875322119225, 'inextricably': 0.06095128398683107, 'tied': 0.051780724243580843, 'participation': 0.057837614336732492, 'fateful': 0.06095128398683107, 'raises': 0.047920323981486691, 'witness': 0.049060672551443189, 'obstruct': 0.065339754879475714, 'participant': 0.06095128398683107, 'scrutiny': 0.057837614336732492, 'administration': 0.048520066211536456, 'whined': 0.065339754879475714, 'commencement': 0.065339754879475714, 'address': 0.04353185308884204, 'coast': 0.049060672551443189, 'guard': 0.045947002901344611, 'academy': 0.051780724243580843, 'series': 0.03890549787407277, 'strange': 0.035674818425356657, 'tweets': 0.040418183438743469, 'thursday': 0.039890112808192962, 'morning': 0.031884472135705798, 'hilariously': 0.065339754879475714, 'victim': 0.045947002901344611, 'greatest': 0.039386612678449021, 'single': 0.03264878731851837, 'witch': 0.050335473793989262, 'hunt': 0.049060672551443189, 'politician': 0.038003033626240898, 'twisted': 0.10356144848716169, 'bad': 0.025413902353257009, 'keeps': 0.035674818425356657, 'focused': 0.038444862358601381, 'campaign': 0.023107530350416492, 'question': 0.025413902353257009, 'generate': 0.050335473793989262, 'core': 0.036029712546098817, 'hope': 0.028172677882613434, 'follow': 0.034056391465956737, 'questions': 0.034056391465956737, 'stop': 0.031170589199778592}\n"
     ]
    }
   ],
   "source": [
    "# create features with tf-idf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "ft_list=[]\n",
    "for i,row in op_ed_articles.iterrows():\n",
    "    article=row['full_text']\n",
    "    ft_list.append(article)\n",
    "#print(ft_list)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.4, # drop words that occur in more than half the articles\n",
    "                             stop_words='english', \n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "#norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "#Applying the vectorizer\n",
    "full_text_tfidf=vectorizer.fit_transform(ft_list)\n",
    "print(\"Number of features: %d\" % full_text_tfidf.get_shape()[1])\n",
    "\n",
    "\n",
    "# #Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = full_text_tfidf.tocsr()\n",
    "\n",
    "# #number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per article\n",
    "tfidf_byarticle = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each article, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_byarticle[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "    \n",
    " #Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "#print('Original sentence:', op_ed_articles['full_text'][2])\n",
    "print('Tf_idf vector:', tfidf_byarticle[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 50.8360155988\n"
     ]
    }
   ],
   "source": [
    "# reduce number of features in tf-idf\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space from 1081 to 100.\n",
    "svd= TruncatedSVD(100)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa_tfidf = lsa.fit_transform(full_text_tfidf)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.195629</td>\n",
       "      <td>-0.136996</td>\n",
       "      <td>-0.081917</td>\n",
       "      <td>-0.087015</td>\n",
       "      <td>0.034639</td>\n",
       "      <td>0.052266</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>-0.123814</td>\n",
       "      <td>0.074180</td>\n",
       "      <td>0.030165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123781</td>\n",
       "      <td>0.199371</td>\n",
       "      <td>-0.064141</td>\n",
       "      <td>0.066511</td>\n",
       "      <td>-0.127108</td>\n",
       "      <td>-0.006951</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>-0.057107</td>\n",
       "      <td>-0.072921</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.207118</td>\n",
       "      <td>-0.110172</td>\n",
       "      <td>-0.042748</td>\n",
       "      <td>-0.054551</td>\n",
       "      <td>0.067294</td>\n",
       "      <td>0.627555</td>\n",
       "      <td>0.191517</td>\n",
       "      <td>0.162841</td>\n",
       "      <td>-0.053989</td>\n",
       "      <td>-0.010135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044783</td>\n",
       "      <td>-0.048705</td>\n",
       "      <td>0.070934</td>\n",
       "      <td>-0.057049</td>\n",
       "      <td>-0.035751</td>\n",
       "      <td>0.010536</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.013381</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.220139</td>\n",
       "      <td>-0.150532</td>\n",
       "      <td>-0.101636</td>\n",
       "      <td>-0.150315</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>-0.178704</td>\n",
       "      <td>0.023079</td>\n",
       "      <td>0.030374</td>\n",
       "      <td>-0.152636</td>\n",
       "      <td>-0.139953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.048016</td>\n",
       "      <td>-0.047894</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>-0.044790</td>\n",
       "      <td>-0.016350</td>\n",
       "      <td>0.054137</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493741</td>\n",
       "      <td>0.312962</td>\n",
       "      <td>0.198156</td>\n",
       "      <td>0.153431</td>\n",
       "      <td>0.090953</td>\n",
       "      <td>-0.019078</td>\n",
       "      <td>-0.045009</td>\n",
       "      <td>0.049372</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093624</td>\n",
       "      <td>-0.021245</td>\n",
       "      <td>0.067245</td>\n",
       "      <td>-0.022356</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>-0.047093</td>\n",
       "      <td>-0.026540</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.088358</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256949</td>\n",
       "      <td>0.103302</td>\n",
       "      <td>0.012789</td>\n",
       "      <td>-0.039456</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>-0.007447</td>\n",
       "      <td>0.038815</td>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.122119</td>\n",
       "      <td>0.322930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004514</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.010287</td>\n",
       "      <td>0.008672</td>\n",
       "      <td>0.011999</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>-0.007518</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.195629 -0.136996 -0.081917 -0.087015  0.034639  0.052266  0.007678   \n",
       "1  0.207118 -0.110172 -0.042748 -0.054551  0.067294  0.627555  0.191517   \n",
       "2  0.220139 -0.150532 -0.101636 -0.150315  0.698596 -0.178704  0.023079   \n",
       "3  0.493741  0.312962  0.198156  0.153431  0.090953 -0.019078 -0.045009   \n",
       "4  0.256949  0.103302  0.012789 -0.039456  0.013495 -0.007447  0.038815   \n",
       "\n",
       "          7         8         9     ...            91        92        93  \\\n",
       "0 -0.123814  0.074180  0.030165     ...      0.123781  0.199371 -0.064141   \n",
       "1  0.162841 -0.053989 -0.010135     ...     -0.044783 -0.048705  0.070934   \n",
       "2  0.030374 -0.152636 -0.139953     ...      0.015931  0.021279  0.011690   \n",
       "3  0.049372  0.010701  0.016947     ...      0.093624 -0.021245  0.067245   \n",
       "4  0.037205  0.122119  0.322930     ...     -0.004514  0.001790  0.010287   \n",
       "\n",
       "         94        95        96        97        98        99  word_count  \n",
       "0  0.066511 -0.127108 -0.006951  0.003398 -0.057107 -0.072921         753  \n",
       "1 -0.057049 -0.035751  0.010536  0.020050  0.019300  0.013381         776  \n",
       "2  0.048016 -0.047894  0.002439 -0.044790 -0.016350  0.054137         686  \n",
       "3 -0.022356  0.012096 -0.047093 -0.026540  0.137600  0.088358         528  \n",
       "4  0.008672  0.011999  0.004227  0.004104  0.005213 -0.007518         725  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Additional features\n",
    "op_ed_articles_numwords = op_ed_articles.filter(items=['word_count'],axis=1)\n",
    "op_ed_articles_numwords.head(n=20)\n",
    "X_train_lsa_tfidf=pd.DataFrame(X_train_lsa_tfidf)\n",
    "data_tfidf = pd.concat([X_train_lsa_tfidf, op_ed_articles_numwords],axis=1)\n",
    "data_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.195629</td>\n",
       "      <td>-0.136996</td>\n",
       "      <td>-0.081917</td>\n",
       "      <td>-0.087015</td>\n",
       "      <td>0.034639</td>\n",
       "      <td>0.052266</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>-0.123814</td>\n",
       "      <td>0.074180</td>\n",
       "      <td>0.030165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199371</td>\n",
       "      <td>-0.064141</td>\n",
       "      <td>0.066511</td>\n",
       "      <td>-0.127108</td>\n",
       "      <td>-0.006951</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>-0.057107</td>\n",
       "      <td>-0.072921</td>\n",
       "      <td>753.0</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.207118</td>\n",
       "      <td>-0.110172</td>\n",
       "      <td>-0.042748</td>\n",
       "      <td>-0.054551</td>\n",
       "      <td>0.067294</td>\n",
       "      <td>0.627555</td>\n",
       "      <td>0.191517</td>\n",
       "      <td>0.162841</td>\n",
       "      <td>-0.053989</td>\n",
       "      <td>-0.010135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048705</td>\n",
       "      <td>0.070934</td>\n",
       "      <td>-0.057049</td>\n",
       "      <td>-0.035751</td>\n",
       "      <td>0.010536</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.013381</td>\n",
       "      <td>776.0</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.220139</td>\n",
       "      <td>-0.150532</td>\n",
       "      <td>-0.101636</td>\n",
       "      <td>-0.150315</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>-0.178704</td>\n",
       "      <td>0.023079</td>\n",
       "      <td>0.030374</td>\n",
       "      <td>-0.152636</td>\n",
       "      <td>-0.139953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>0.048016</td>\n",
       "      <td>-0.047894</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>-0.044790</td>\n",
       "      <td>-0.016350</td>\n",
       "      <td>0.054137</td>\n",
       "      <td>686.0</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493741</td>\n",
       "      <td>0.312962</td>\n",
       "      <td>0.198156</td>\n",
       "      <td>0.153431</td>\n",
       "      <td>0.090953</td>\n",
       "      <td>-0.019078</td>\n",
       "      <td>-0.045009</td>\n",
       "      <td>0.049372</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021245</td>\n",
       "      <td>0.067245</td>\n",
       "      <td>-0.022356</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>-0.047093</td>\n",
       "      <td>-0.026540</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.088358</td>\n",
       "      <td>528.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256949</td>\n",
       "      <td>0.103302</td>\n",
       "      <td>0.012789</td>\n",
       "      <td>-0.039456</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>-0.007447</td>\n",
       "      <td>0.038815</td>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.122119</td>\n",
       "      <td>0.322930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.010287</td>\n",
       "      <td>0.008672</td>\n",
       "      <td>0.011999</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>-0.007518</td>\n",
       "      <td>725.0</td>\n",
       "      <td>392.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.195629 -0.136996 -0.081917 -0.087015  0.034639  0.052266  0.007678   \n",
       "1  0.207118 -0.110172 -0.042748 -0.054551  0.067294  0.627555  0.191517   \n",
       "2  0.220139 -0.150532 -0.101636 -0.150315  0.698596 -0.178704  0.023079   \n",
       "3  0.493741  0.312962  0.198156  0.153431  0.090953 -0.019078 -0.045009   \n",
       "4  0.256949  0.103302  0.012789 -0.039456  0.013495 -0.007447  0.038815   \n",
       "\n",
       "        7         8         9    ...         92        93        94   \\\n",
       "0 -0.123814  0.074180  0.030165  ...    0.199371 -0.064141  0.066511   \n",
       "1  0.162841 -0.053989 -0.010135  ...   -0.048705  0.070934 -0.057049   \n",
       "2  0.030374 -0.152636 -0.139953  ...    0.021279  0.011690  0.048016   \n",
       "3  0.049372  0.010701  0.016947  ...   -0.021245  0.067245 -0.022356   \n",
       "4  0.037205  0.122119  0.322930  ...    0.001790  0.010287  0.008672   \n",
       "\n",
       "        95        96        97        98        99     100    101  \n",
       "0 -0.127108 -0.006951  0.003398 -0.057107 -0.072921  753.0  391.0  \n",
       "1 -0.035751  0.010536  0.020050  0.019300  0.013381  776.0  371.0  \n",
       "2 -0.047894  0.002439 -0.044790 -0.016350  0.054137  686.0  319.0  \n",
       "3  0.012096 -0.047093 -0.026540  0.137600  0.088358  528.0  297.0  \n",
       "4  0.011999  0.004227  0.004104  0.005213 -0.007518  725.0  392.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at some metrics around this sentence.\n",
    "unique_word_counts = []\n",
    "total_punctuation_counts = []\n",
    "for i, row in op_ed_articles.iterrows():\n",
    "    total_words = [token for token in row['full_text_tokenized'] if not token.is_punct]\n",
    "    total_punct = [token for token in row['full_text_tokenized'] if token.is_punct]\n",
    "    unique_words = set([token.text for token in total_words])\n",
    "    unique_wc = len(unique_words)\n",
    "    punc_count = len(total_punct)\n",
    "    unique_word_counts.append(unique_wc)\n",
    "    total_punctuation_counts.append(punc_count)\n",
    "unique_words = pd.Series(unique_word_counts)\n",
    "punctuation = pd.Series(total_punctuation_counts)\n",
    "\n",
    "data_tfidf = pd.concat([data_tfidf, unique_words],axis=1)\n",
    "#data_tfidf = pd.concat([data_tfidf, punctuation],axis=1)\n",
    "data_tfidf = data_tfidf.T.reset_index(drop=True).T\n",
    "data_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for tf-idf dataset\n",
    "Y = op_ed_articles['byline']\n",
    "X = data_tfidf  \n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X, \n",
    "                                                    Y,stratify=Y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.878260869565\n",
      "\n",
      "Test set score: 0.636363636364\n"
     ]
    }
   ],
   "source": [
    "# using tf-idf dataset\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('Training set score:', lr.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\nTest set score:', lr.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "I was able improve the test set score by about 5 points by adding word count features and reducing the feature set using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
